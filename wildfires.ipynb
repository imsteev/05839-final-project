{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = 1992\n",
    "COLS_NEEDED = [\n",
    "    \"FIRE_YEAR\",\n",
    "    \"DISCOVERY_DATE\",\n",
    "    \"DISCOVERY_DOY\",\n",
    "    \"DISCOVERY_TIME\",\n",
    "    \"STAT_CAUSE_CODE\",\n",
    "    \"STAT_CAUSE_DESCR\",\n",
    "    \"CONT_DATE\",\n",
    "    \"CONT_DOY\",\n",
    "    \"CONT_TIME\",\n",
    "    \"FIRE_SIZE\",\n",
    "    \"FIRE_SIZE_CLASS\",\n",
    "    \"LATITUDE\",\n",
    "    \"LONGITUDE\",\n",
    "    \"STATE\",\n",
    "    \"COUNTY\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (10,11,12,18,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "with open('./wildfires_%d.csv' % YEAR) as csvfile:\n",
    "    df = pd.read_csv(csvfile)\n",
    "    df = df[COLS_NEEDED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(day, Y):\n",
    "    seasons = [('winter', (date(Y,  1,  1),  date(Y,  3, 20))),\n",
    "              ('spring', (date(Y,  3, 21),  date(Y,  6, 20))),\n",
    "              ('summer', (date(Y,  6, 21),  date(Y,  9, 22))),\n",
    "              ('autumn', (date(Y,  9, 23),  date(Y, 12, 20))),\n",
    "              ('winter', (date(Y, 12, 21),  date(Y, 12, 31)))]\n",
    "    for season in seasons:\n",
    "        name = season[0]\n",
    "        start, end = season[1]\n",
    "        if (start.timetuple().tm_yday <= day <= end.timetuple().tm_yday):\n",
    "            return name\n",
    "    return None\n",
    "\n",
    "def julian_to_datetime(jd_series):\n",
    "    # https://www.kaggle.com/rtatman/188-million-us-wildfires/discussion/39627#222290\n",
    "    epoch = pd.to_datetime(0, unit='s').to_julian_date()\n",
    "    return pd.to_datetime(jd_series - epoch, unit='D')\n",
    "\n",
    "def difference_in_seconds():\n",
    "    start_times = df['DISCOVERY_TIME']\n",
    "    end_times = df['CONT_TIME']\n",
    "    return pd.to_datetime(end_times) - pd.to_datetime(start_times)\n",
    "\n",
    "def num_to_time(num_time):\n",
    "    # num_time is in 24-hour format - so 0 to 2359\n",
    "    chars = list(str(int(num_time)))\n",
    "    res = []\n",
    "    for i in range(len(chars)-1, -1, -1):\n",
    "      res.append(chars[i])\n",
    "      if len(res) == 2:\n",
    "        res.append(\":\")\n",
    "    result = ''.join(res[::-1])\n",
    "    if len(result) == 1: result = \"00:0\" + result\n",
    "    if result[0] == \":\": result = \"00\" + result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean\n",
    "df = df.dropna(subset=['CONT_DATE', 'DISCOVERY_DATE', 'CONT_TIME', 'DISCOVERY_TIME'])\n",
    "df['CONT_TIME'] = df.apply(lambda row: num_to_time(row.CONT_TIME), axis=1)\n",
    "df['DISCOVERY_TIME'] = df.apply(lambda row: num_to_time(row.DISCOVERY_TIME), axis=1)\n",
    "df['CONT_DATE'] = df.apply(lambda row: julian_to_datetime(row.CONT_DATE), axis=1)\n",
    "df['DISCOVERY_DATE'] = df.apply(lambda row: julian_to_datetime(row.DISCOVERY_DATE),axis=1)\n",
    "df['season'] = df.apply(lambda row: get_season(row.DISCOVERY_DOY,YEAR), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_disc_date = pd.to_datetime(df['DISCOVERY_DATE'].dt.strftime(\"%Y-%m-%d\") + ' ' + df['DISCOVERY_TIME'])\n",
    "full_cont_date = pd.to_datetime(df['CONT_DATE'].dt.strftime(\"%Y-%m-%d\") + ' ' + df['CONT_TIME'])\n",
    "df['duration'] = full_cont_date - full_disc_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_STATE_CODES = ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "\n",
    "# https://en.wikipedia.org/wiki/List_of_regions_of_the_United_States\n",
    "SEASONS = ['winter','spring','summer','autumn']\n",
    "STAT_CAUSE_CODES = list(range(1,14))\n",
    "\n",
    "REGIONS = {\n",
    "    'northeast': ['CT','ME','MA','NH','RI','VT','NJ','NY','PA'],\n",
    "    'midwest': ['IL','IN','MI','OH','WI','IA','KS','MN','MO','NE','ND','SD'],\n",
    "    'west': ['AZ','CO','ID','MT','NV','NM','UT','WY','AK','CA','HI','OR','WA'],\n",
    "    'south': ['DE','FL','GA','MD','NC','SC','VA','DC','WV','AL','KY','MS','TN','AR','LA','OK','TX']\n",
    "}\n",
    "\n",
    "def get_region(state_code):\n",
    "    for region in REGIONS:\n",
    "        if state_code in REGIONS[region]: return region\n",
    "    return None\n",
    "\n",
    "df['region'] = df.apply(lambda row: get_region(row.STATE), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create classifier\n",
    "# - extract features for each row\n",
    "# - create labels for each row (this should just be getting the fire class size and mapping it to an integer)\n",
    "# - split data into train + test sets (shuffle data first?)\n",
    "# - train data using a model (need to look this up)\n",
    "# - test for accuracy\n",
    "\n",
    "label_names = [chr(ord('A') + i) for i in range(ord('G') - ord('A') + 1)]\n",
    "\n",
    "# features: 'state', 'season', 'cause', 'duration' (maybe)\n",
    "\n",
    "def extract_features(row):\n",
    "    regions_list = list(REGIONS.keys())\n",
    "    return [SEASONS.index(row.season), int(row.STAT_CAUSE_CODE), regions_list.index(row.region)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = df[['STAT_CAUSE_CODE', 'season', 'region']]\n",
    "X = [extract_features(row) for _,row in feature_df.iterrows()]\n",
    "y = df['FIRE_SIZE_CLASS'].map(lambda fire_class: ord(fire_class) - ord('A'))\n",
    "\n",
    "# https://stackoverflow.com/a/4602224/8109239\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return np.asarray(a)[p], np.asarray(b)[p]\n",
    "\n",
    "X,y = unison_shuffled_copies(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "train_size = 15000\n",
    "test_size = len(X) - train_size\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_test, y_test = X[train_size+1:], y[train_size+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.595054683785\n"
     ]
    }
   ],
   "source": [
    "# Use naive bayes because features are independent of each other\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0 days 02:40:00\n",
      "1       0 days 23:00:00\n",
      "2       2 days 02:30:00\n",
      "3       0 days 00:10:00\n",
      "4       0 days 00:30:00\n",
      "5       0 days 03:00:00\n",
      "6       0 days 01:57:00\n",
      "7       0 days 01:30:00\n",
      "8       0 days 18:00:00\n",
      "9       1 days 01:29:00\n",
      "10      0 days 07:59:00\n",
      "11      0 days 05:00:00\n",
      "12      0 days 03:00:00\n",
      "13      0 days 06:15:00\n",
      "14      0 days 03:29:00\n",
      "15      0 days 04:58:00\n",
      "16      0 days 01:20:00\n",
      "17      0 days 19:00:00\n",
      "18      0 days 06:59:00\n",
      "19      0 days 03:30:00\n",
      "20      0 days 23:00:00\n",
      "21      0 days 02:30:00\n",
      "22      1 days 00:30:00\n",
      "23      0 days 02:00:00\n",
      "24      0 days 01:45:00\n",
      "25      0 days 01:25:00\n",
      "26      1 days 03:45:00\n",
      "27      0 days 12:00:00\n",
      "28      0 days 15:00:00\n",
      "29      0 days 07:30:00\n",
      "              ...      \n",
      "67868   0 days 00:19:00\n",
      "67869   0 days 00:20:00\n",
      "67870   0 days 00:45:00\n",
      "67871   0 days 00:28:00\n",
      "67872   0 days 01:04:00\n",
      "67873   0 days 00:35:00\n",
      "67874   0 days 00:14:00\n",
      "67875   0 days 00:30:00\n",
      "67876   0 days 05:30:00\n",
      "67877   0 days 00:45:00\n",
      "67878   0 days 00:15:00\n",
      "67879   0 days 01:57:00\n",
      "67880   0 days 00:10:00\n",
      "67881   0 days 01:07:00\n",
      "67882   0 days 00:55:00\n",
      "67883   0 days 01:00:00\n",
      "67884   0 days 00:35:00\n",
      "67885   0 days 02:10:00\n",
      "67886   0 days 03:00:00\n",
      "67887   0 days 00:05:00\n",
      "67889   0 days 01:15:00\n",
      "67890   0 days 00:11:00\n",
      "67891   1 days 00:45:00\n",
      "67892   0 days 00:29:00\n",
      "67893   0 days 00:20:00\n",
      "67894   0 days 00:29:00\n",
      "67930   0 days 00:02:00\n",
      "67931   0 days 00:02:00\n",
      "67932   0 days 00:41:00\n",
      "67933   0 days 00:15:00\n",
      "Name: duration, Length: 36031, dtype: timedelta64[ns]\n"
     ]
    }
   ],
   "source": [
    "print(df['duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
