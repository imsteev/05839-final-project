{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = 1992\n",
    "COLS_NEEDED = [\n",
    "    \"FIRE_YEAR\",\n",
    "    \"DISCOVERY_DATE\",\n",
    "    \"DISCOVERY_DOY\",\n",
    "    \"DISCOVERY_TIME\",\n",
    "    \"STAT_CAUSE_CODE\",\n",
    "    \"STAT_CAUSE_DESCR\",\n",
    "    \"CONT_DATE\",\n",
    "    \"CONT_DOY\",\n",
    "    \"CONT_TIME\",\n",
    "    \"FIRE_SIZE\",\n",
    "    \"FIRE_SIZE_CLASS\",\n",
    "    \"LATITUDE\",\n",
    "    \"LONGITUDE\",\n",
    "    \"STATE\",\n",
    "    \"COUNTY\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (10,11,12,18,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "with open('./wildfires_%d.csv' % YEAR) as csvfile:\n",
    "    df = pd.read_csv(csvfile)\n",
    "    df = df[COLS_NEEDED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n"
     ]
    }
   ],
   "source": [
    "def get_season(day, Y):\n",
    "    seasons = [('winter', (date(Y,  1,  1),  date(Y,  3, 20))),\n",
    "              ('spring', (date(Y,  3, 21),  date(Y,  6, 20))),\n",
    "              ('summer', (date(Y,  6, 21),  date(Y,  9, 22))),\n",
    "              ('autumn', (date(Y,  9, 23),  date(Y, 12, 20))),\n",
    "              ('winter', (date(Y, 12, 21),  date(Y, 12, 31)))]\n",
    "    for season in seasons:\n",
    "        name = season[0]\n",
    "        start, end = season[1]\n",
    "        if (start.timetuple().tm_yday <= day <= end.timetuple().tm_yday):\n",
    "            return name\n",
    "    return None\n",
    "\n",
    "def julian_to_datetime(jd_series):\n",
    "    # https://www.kaggle.com/rtatman/188-million-us-wildfires/discussion/39627#222290\n",
    "    epoch = pd.to_datetime(0, unit='s').to_julian_date()\n",
    "    return pd.to_datetime(jd_series - epoch, unit='D')\n",
    "\n",
    "def difference_in_seconds():\n",
    "    start_times = df['DISCOVERY_TIME']\n",
    "    end_times = df['CONT_TIME']\n",
    "    return pd.to_datetime(end_times) - pd.to_datetime(start_times)\n",
    "\n",
    "def num_to_time(num_time):\n",
    "    # num_time is in 24-hour format - so 0 to 2359\n",
    "    chars = list(str(int(num_time)))\n",
    "    res = []\n",
    "    for i in range(len(chars)-1, -1, -1):\n",
    "      res.append(chars[i])\n",
    "      if len(res) == 2:\n",
    "        res.append(\":\")\n",
    "    result = ''.join(res[::-1])\n",
    "    if len(result) == 1: result = \"00:0\" + result\n",
    "    if result[0] == \":\": result = \"00\" + result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean\n",
    "df = df.dropna(subset=['CONT_DATE', 'DISCOVERY_DATE', 'CONT_TIME', 'DISCOVERY_TIME'])\n",
    "df['CONT_TIME'] = df.apply(lambda row: num_to_time(row.CONT_TIME), axis=1)\n",
    "df['DISCOVERY_TIME'] = df.apply(lambda row: num_to_time(row.DISCOVERY_TIME), axis=1)\n",
    "df['CONT_DATE'] = df.apply(lambda row: julian_to_datetime(row.CONT_DATE), axis=1)\n",
    "df['DISCOVERY_DATE'] = df.apply(lambda row: julian_to_datetime(row.DISCOVERY_DATE),axis=1)\n",
    "df['season'] = df.apply(lambda row: get_season(row.DISCOVERY_DOY,YEAR), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_disc_date = pd.to_datetime(df['DISCOVERY_DATE'].dt.strftime(\"%Y-%m-%d\") + ' ' + df['DISCOVERY_TIME'])\n",
    "full_cont_date = pd.to_datetime(df['CONT_DATE'].dt.strftime(\"%Y-%m-%d\") + ' ' + df['CONT_TIME'])\n",
    "df['duration'] = full_cont_date - full_disc_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_STATE_CODES = ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "SEASONS = ['winter','spring','summer','autumn']\n",
    "STAT_CAUSE_CODES = list(range(1,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create classifier\n",
    "# - extract features for each row\n",
    "# - create labels for each row (this should just be getting the fire class size and mapping it to an integer)\n",
    "# - split data into train + test sets (shuffle data first?)\n",
    "# - train data using a model (need to look this up)\n",
    "# - test for accuracy\n",
    "\n",
    "label_names = [chr(ord('A') + i) for i in range(ord('G') - ord('A') + 1)]\n",
    "\n",
    "# features: 'state', 'season', 'cause', 'duration' (maybe)\n",
    "\n",
    "def extract_features(row):\n",
    "    return [US_STATE_CODES.index(row.STATE), SEASONS.index(row.season), int(row.STAT_CAUSE_CODE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = df[['STATE', 'STAT_CAUSE_CODE', 'season']]\n",
    "X = [extract_features(row) for _,row in feature_df.iterrows()]\n",
    "y = df['FIRE_SIZE_CLASS'].map(lambda fire_class: ord(fire_class) - ord('A'))\n",
    "\n",
    "# https://stackoverflow.com/a/4602224/8109239\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return np.asarray(a)[p], np.asarray(b)[p]\n",
    "\n",
    "X,y = unison_shuffled_copies(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "train_size = 15000\n",
    "test_size = len(X) - train_size\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_test, y_test = X[train_size+1:], y[train_size+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(X, y)\n",
    "print(clf.predict([[0, 5, 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
