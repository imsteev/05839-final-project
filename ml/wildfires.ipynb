{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = 1992\n",
    "COLS_NEEDED = [\n",
    "    \"FIRE_YEAR\",\n",
    "    \"DISCOVERY_DATE\",\n",
    "    \"DISCOVERY_DOY\",\n",
    "    \"DISCOVERY_TIME\",\n",
    "    \"STAT_CAUSE_CODE\",\n",
    "    \"STAT_CAUSE_DESCR\",\n",
    "    \"CONT_DATE\",\n",
    "    \"CONT_DOY\",\n",
    "    \"CONT_TIME\",\n",
    "    \"FIRE_SIZE\",\n",
    "    \"FIRE_SIZE_CLASS\",\n",
    "    \"LATITUDE\",\n",
    "    \"LONGITUDE\",\n",
    "    \"STATE\",\n",
    "    \"COUNTY\"\n",
    "]\n",
    "\n",
    "COLS_NEEDED_FOR_CLASSIFICATION = [\n",
    "    \"DISCOVERY_DATE\",\n",
    "    \"DISCOVERY_DOY\",\n",
    "    \"DISCOVERY_TIME\",\n",
    "    \"STAT_CAUSE_CODE\",\n",
    "    \"CONT_DATE\",\n",
    "    \"CONT_TIME\",\n",
    "    \"FIRE_SIZE_CLASS\",\n",
    "    \"STATE\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (10,11,12,18,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "with open('./wildfires_%d.csv' % YEAR) as csvfile:\n",
    "    df = pd.read_csv(csvfile)\n",
    "    df = df[COLS_NEEDED_FOR_CLASSIFICATION]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(day, Y):\n",
    "    seasons = [('winter', (date(Y,  1,  1),  date(Y,  3, 20))),\n",
    "              ('spring', (date(Y,  3, 21),  date(Y,  6, 20))),\n",
    "              ('summer', (date(Y,  6, 21),  date(Y,  9, 22))),\n",
    "              ('autumn', (date(Y,  9, 23),  date(Y, 12, 20))),\n",
    "              ('winter', (date(Y, 12, 21),  date(Y, 12, 31)))]\n",
    "    for season in seasons:\n",
    "        name = season[0]\n",
    "        start, end = season[1]\n",
    "        if (start.timetuple().tm_yday <= day <= end.timetuple().tm_yday):\n",
    "            return name\n",
    "    return None\n",
    "\n",
    "def julian_to_datetime(jd_series):\n",
    "    # https://www.kaggle.com/rtatman/188-million-us-wildfires/discussion/39627#222290\n",
    "    epoch = pd.to_datetime(0, unit='s').to_julian_date()\n",
    "    return pd.to_datetime(jd_series - epoch, unit='D')\n",
    "\n",
    "def difference_in_seconds():\n",
    "    start_times = df['DISCOVERY_TIME']\n",
    "    end_times = df['CONT_TIME']\n",
    "    return pd.to_datetime(end_times) - pd.to_datetime(start_times)\n",
    "\n",
    "def num_to_time(num_time):\n",
    "    # num_time is in 24-hour format - so 0 to 2359\n",
    "    chars = list(str(int(num_time)))\n",
    "    res = []\n",
    "    for i in range(len(chars)-1, -1, -1):\n",
    "      res.append(chars[i])\n",
    "      if len(res) == 2:\n",
    "        res.append(\":\")\n",
    "    result = ''.join(res[::-1])\n",
    "    if len(result) == 1: result = \"00:0\" + result\n",
    "    if result[0] == \":\": result = \"00\" + result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean\n",
    "df = df.dropna(subset=['CONT_DATE', 'DISCOVERY_DATE', 'CONT_TIME', 'DISCOVERY_TIME', 'DISCOVERY_DOY', 'STAT_CAUSE_CODE'])\n",
    "df['CONT_TIME'] = df.apply(lambda row: num_to_time(row.CONT_TIME), axis=1)\n",
    "df['DISCOVERY_TIME'] = df.apply(lambda row: num_to_time(row.DISCOVERY_TIME), axis=1)\n",
    "df['CONT_DATE'] = df.apply(lambda row: julian_to_datetime(row.CONT_DATE), axis=1)\n",
    "df['DISCOVERY_DATE'] = df.apply(lambda row: julian_to_datetime(row.DISCOVERY_DATE),axis=1)\n",
    "df['season'] = df.apply(lambda row: get_season(row.DISCOVERY_DOY,YEAR), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_disc_date = pd.to_datetime(df['DISCOVERY_DATE'].dt.strftime(\"%Y-%m-%d\") + ' ' + df['DISCOVERY_TIME'])\n",
    "full_cont_date = pd.to_datetime(df['CONT_DATE'].dt.strftime(\"%Y-%m-%d\") + ' ' + df['CONT_TIME'])\n",
    "df['duration'] = full_cont_date - full_disc_date\n",
    "\n",
    "# with open(\"./wildfires_dates.csv\", \"w\") as csvfile:\n",
    "#     df.to_csv(csvfile,\n",
    "#               index=False, \n",
    "#               columns=['FIRE_SIZE', 'DISCOVERY_DATE', 'LATITUDE', 'LONGITUDE', 'duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_STATE_CODES = ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'PR', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "\n",
    "# https://en.wikipedia.org/wiki/List_of_regions_of_the_United_States\n",
    "SEASONS = ['winter','spring','summer','autumn']\n",
    "STAT_CAUSE_CODES = list(range(1,14))\n",
    "\n",
    "REGIONS = {\n",
    "    'northeast': ['CT','ME','MA','NH','RI','VT','NJ','NY','PA'],\n",
    "    'midwest': ['IL','IN','MI','OH','WI','IA','KS','MN','MO','NE','ND','SD'],\n",
    "    'west': ['AZ','CO','ID','MT','NV','NM','UT','WY','AK','CA','HI','OR','WA'],\n",
    "    'south': ['DE','FL','GA','MD','NC','SC','VA','DC','WV','AL','KY','MS','TN','AR','LA','OK','TX', 'PR']\n",
    "}\n",
    "\n",
    "def get_region(state_code):\n",
    "    for region in REGIONS:\n",
    "        if state_code in REGIONS[region]: return region\n",
    "    print(state_code)\n",
    "    return None\n",
    "\n",
    "df['region'] = df.apply(lambda row: get_region(row.STATE), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create classifier\n",
    "# - extract features for each row\n",
    "# - create labels for each row (this should just be getting the fire class size and mapping it to an integer)\n",
    "# - split data into train + test sets (shuffle data first?)\n",
    "# - train data using a model (need to look this up)\n",
    "# - test for accuracy\n",
    "\n",
    "label_names = [chr(ord('A') + i) for i in range(ord('G') - ord('A') + 1)]\n",
    "\n",
    "# features: 'state', 'season', 'cause', 'duration' (maybe)\n",
    "\n",
    "def extract_features(row):\n",
    "    regions_list = list(REGIONS.keys())\n",
    "#     duration_min = row.duration.days * 24 * 60 + row.duration.seconds//3600\n",
    "    return [SEASONS.index(row.season), int(row.STAT_CAUSE_CODE), regions_list.index(row.region)]\n",
    "\n",
    "feature_df = df[['STAT_CAUSE_CODE', 'season', 'region', 'duration']]\n",
    "X = [extract_features(row) for _,row in feature_df.iterrows()]\n",
    "y = df['FIRE_SIZE_CLASS'].map(lambda fire_class: ord(fire_class) - ord('A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/4602224/8109239\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return np.asarray(a)[p], np.asarray(b)[p]\n",
    "\n",
    "X,y = unison_shuffled_copies(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.582755111481\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and test sets\n",
    "TRAIN_FRAC = 0.7\n",
    "TRAIN_SIZE = round(TRAIN_FRAC * len(X))\n",
    "X_train, y_train = X[:TRAIN_SIZE], y[:TRAIN_SIZE]\n",
    "X_test, y_test = X[TRAIN_SIZE:], y[TRAIN_SIZE:]\n",
    "\n",
    "# Use naive bayes because features are independent of each other\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save relevant data used for classification\n",
    "# for year in range(1992,2016):\n",
    "#     with open(\"./wildfires_%d.csv\" % year) as csvtoread:\n",
    "#         df = pd.read_csv(csvtoread)\n",
    "#         with open(\"./csvsForClassification/trimmed_wildfires_%d.csv\" % year, \"w\") as csvtowrite:\n",
    "#             df.to_csv(csvtowrite, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
