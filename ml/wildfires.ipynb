{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = 1992\n",
    "COLS_NEEDED = [\n",
    "    \"FIRE_YEAR\",\n",
    "    \"DISCOVERY_DATE\",\n",
    "    \"DISCOVERY_DOY\",\n",
    "    \"DISCOVERY_TIME\",\n",
    "    \"STAT_CAUSE_CODE\",\n",
    "    \"STAT_CAUSE_DESCR\",\n",
    "    \"CONT_DATE\",\n",
    "    \"CONT_DOY\",\n",
    "    \"CONT_TIME\",\n",
    "    \"FIRE_SIZE\",\n",
    "    \"FIRE_SIZE_CLASS\",\n",
    "    \"LATITUDE\",\n",
    "    \"LONGITUDE\",\n",
    "    \"STATE\",\n",
    "    \"COUNTY\"\n",
    "]\n",
    "\n",
    "COLS_NEEDED_FOR_CLASSIFICATION = [\n",
    "    \"DISCOVERY_DATE\",\n",
    "    \"DISCOVERY_DOY\",\n",
    "    \"DISCOVERY_TIME\",\n",
    "    \"STAT_CAUSE_CODE\",\n",
    "    \"CONT_DATE\",\n",
    "    \"CONT_TIME\",\n",
    "    \"FIRE_SIZE_CLASS\",\n",
    "    \"STATE\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (10,11,12,18,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "with open('./wildfires_%d.csv' % YEAR) as csvfile:\n",
    "    df = pd.read_csv(csvfile)\n",
    "    df = df[COLS_NEEDED_FOR_CLASSIFICATION]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(day, Y):\n",
    "    seasons = [('winter', (date(Y,  1,  1),  date(Y,  3, 20))),\n",
    "              ('spring', (date(Y,  3, 21),  date(Y,  6, 20))),\n",
    "              ('summer', (date(Y,  6, 21),  date(Y,  9, 22))),\n",
    "              ('autumn', (date(Y,  9, 23),  date(Y, 12, 20))),\n",
    "              ('winter', (date(Y, 12, 21),  date(Y, 12, 31)))]\n",
    "    for season in seasons:\n",
    "        name = season[0]\n",
    "        start, end = season[1]\n",
    "        if (start.timetuple().tm_yday <= day <= end.timetuple().tm_yday):\n",
    "            return name\n",
    "    return None\n",
    "\n",
    "def julian_to_datetime(jd_series):\n",
    "    # https://www.kaggle.com/rtatman/188-million-us-wildfires/discussion/39627#222290\n",
    "    epoch = pd.to_datetime(0, unit='s').to_julian_date()\n",
    "    return pd.to_datetime(jd_series - epoch, unit='D')\n",
    "\n",
    "def difference_in_seconds():\n",
    "    start_times = df['DISCOVERY_TIME']\n",
    "    end_times = df['CONT_TIME']\n",
    "    return pd.to_datetime(end_times) - pd.to_datetime(start_times)\n",
    "\n",
    "def num_to_time(num_time):\n",
    "    # num_time is in 24-hour format - so 0 to 2359\n",
    "    chars = list(str(int(num_time)))\n",
    "    res = []\n",
    "    for i in range(len(chars)-1, -1, -1):\n",
    "      res.append(chars[i])\n",
    "      if len(res) == 2:\n",
    "        res.append(\":\")\n",
    "    result = ''.join(res[::-1])\n",
    "    if len(result) == 1: result = \"00:0\" + result\n",
    "    if result[0] == \":\": result = \"00\" + result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean\n",
    "df = df.dropna(subset=['CONT_DATE', 'DISCOVERY_DATE', 'CONT_TIME', 'DISCOVERY_TIME', 'DISCOVERY_DOY', 'STAT_CAUSE_CODE'])\n",
    "df['CONT_TIME'] = df.apply(lambda row: num_to_time(row.CONT_TIME), axis=1)\n",
    "df['DISCOVERY_TIME'] = df.apply(lambda row: num_to_time(row.DISCOVERY_TIME), axis=1)\n",
    "df['CONT_DATE'] = df.apply(lambda row: julian_to_datetime(row.CONT_DATE), axis=1)\n",
    "df['DISCOVERY_DATE'] = df.apply(lambda row: julian_to_datetime(row.DISCOVERY_DATE),axis=1)\n",
    "df['season'] = df.apply(lambda row: get_season(row.DISCOVERY_DOY,YEAR), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_disc_date = pd.to_datetime(df['DISCOVERY_DATE'].dt.strftime(\"%Y-%m-%d\") + ' ' + df['DISCOVERY_TIME'])\n",
    "full_cont_date = pd.to_datetime(df['CONT_DATE'].dt.strftime(\"%Y-%m-%d\") + ' ' + df['CONT_TIME'])\n",
    "df['duration'] = full_cont_date - full_disc_date\n",
    "\n",
    "# with open(\"./wildfires_dates.csv\", \"w\") as csvfile:\n",
    "#     df.to_csv(csvfile,\n",
    "#               index=False, \n",
    "#               columns=['FIRE_SIZE', 'DISCOVERY_DATE', 'LATITUDE', 'LONGITUDE', 'duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_STATE_CODES = ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'PR', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "\n",
    "# https://en.wikipedia.org/wiki/List_of_regions_of_the_United_States\n",
    "SEASONS = ['winter','spring','summer','autumn']\n",
    "STAT_CAUSE_CODES = list(range(1,14))\n",
    "\n",
    "REGIONS = {\n",
    "    'northeast': ['CT','ME','MA','NH','RI','VT','NJ','NY','PA'],\n",
    "    'midwest': ['IL','IN','MI','OH','WI','IA','KS','MN','MO','NE','ND','SD'],\n",
    "    'west': ['AZ','CO','ID','MT','NV','NM','UT','WY','AK','CA','HI','OR','WA'],\n",
    "    'south': ['DE','FL','GA','MD','NC','SC','VA','DC','WV','AL','KY','MS','TN','AR','LA','OK','TX', 'PR']\n",
    "}\n",
    "\n",
    "def get_region(state_code):\n",
    "    for region in REGIONS:\n",
    "        if state_code in REGIONS[region]: return region\n",
    "    print(state_code)\n",
    "    return None\n",
    "\n",
    "df['region'] = df.apply(lambda row: get_region(row.STATE), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create classifier\n",
    "# - extract features for each row\n",
    "# - create labels for each row (this should just be getting the fire class size and mapping it to an integer)\n",
    "# - split data into train + test sets (shuffle data first?)\n",
    "# - train data using a model (need to look this up)\n",
    "# - test for accuracy\n",
    "\n",
    "label_names = [chr(ord('A') + i) for i in range(ord('G') - ord('A') + 1)]\n",
    "\n",
    "# features: 'state', 'season', 'cause', 'duration' (maybe)\n",
    "\n",
    "def extract_features(row):\n",
    "    regions_list = list(REGIONS.keys())\n",
    "#     duration_min = row.duration.days * 24 * 60 + row.duration.seconds//3600\n",
    "    return [SEASONS.index(row.season), int(row.STAT_CAUSE_CODE), regions_list.index(row.region)]\n",
    "\n",
    "feature_df = df[['STAT_CAUSE_CODE', 'season', 'region', 'duration']]\n",
    "X = [extract_features(row) for _,row in feature_df.iterrows()]\n",
    "y = df['FIRE_SIZE_CLASS'].map(lambda fire_class: ord(fire_class) - ord('A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/4602224/8109239\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return np.asarray(a)[p], np.asarray(b)[p]\n",
    "\n",
    "X,y = unison_shuffled_copies(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.582755111481\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and test sets\n",
    "TRAIN_FRAC = 0.7\n",
    "TRAIN_SIZE = round(TRAIN_FRAC * len(X))\n",
    "X_train, y_train = X[:TRAIN_SIZE], y[:TRAIN_SIZE]\n",
    "X_test, y_test = X[TRAIN_SIZE:], y[TRAIN_SIZE:]\n",
    "\n",
    "# Use naive bayes because features are independent of each other\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save relevant data used for classification\n",
    "# for year in range(1992,2016):\n",
    "#     with open(\"./wildfires_%d.csv\" % year) as csvtoread:\n",
    "#         df = pd.read_csv(csvtoread)\n",
    "#         with open(\"./csvsForClassification/trimmed_wildfires_%d.csv\" % year, \"w\") as csvtowrite:\n",
    "#             df.to_csv(csvtowrite, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (10,11,12,18,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "class WildfireClassifier(object):\n",
    "    COLS = [\n",
    "        \"DISCOVERY_DATE\",\n",
    "        \"DISCOVERY_DOY\",\n",
    "        \"DISCOVERY_TIME\",\n",
    "        \"STAT_CAUSE_CODE\",\n",
    "        \"STAT_CAUSE_DESCR\",\n",
    "        \"CONT_DATE\",\n",
    "        \"CONT_TIME\",\n",
    "        \"FIRE_SIZE_CLASS\",\n",
    "        \"FIRE_SIZE\",\n",
    "        \"STATE\"\n",
    "    ]\n",
    "\n",
    "    REGIONS = {\n",
    "        'northeast': ['CT','ME','MA','NH','RI','VT','NJ','NY','PA'],\n",
    "        'midwest': ['IL','IN','MI','OH','WI','IA','KS','MN','MO','NE','ND','SD'],\n",
    "        'west': ['AZ','CO','ID','MT','NV','NM','UT','WY','AK','CA','HI','OR','WA'],\n",
    "        'south': ['DE','FL','GA','MD','NC','SC','VA','DC','WV','AL','KY','MS','TN','AR','LA','OK','TX', 'PR']\n",
    "    }\n",
    "    \n",
    "    US_STATE_CODES = ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'PR', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "    # https://en.wikipedia.org/wiki/List_of_regions_of_the_United_States\n",
    "    SEASONS = ['winter','spring','summer','autumn']\n",
    "    STAT_CAUSE_CODES = list(range(1,14))\n",
    "    \n",
    "    def __init__(self, fname, year):\n",
    "        self.cleaned = False\n",
    "        self.year = year\n",
    "        with open(fname) as csvfile:\n",
    "            self.df = pd.read_csv(csvfile)\n",
    "            self.df = self.df[WildfireClassifier.COLS]\n",
    "        \n",
    "#         for name, group in self.df.groupby('STAT_CAUSE_DESCR'):\n",
    "#             print(name, len(group))\n",
    "#         print(self.df[['FIRE_SIZE', 'FIRE_SIZE_CLASS']].drop_duplicates())\n",
    "            \n",
    "    def get_season(self, day, Y):\n",
    "        seasons = [('winter', (date(Y,  1,  1),  date(Y,  3, 20))),\n",
    "                  ('spring', (date(Y,  3, 21),  date(Y,  6, 20))),\n",
    "                  ('summer', (date(Y,  6, 21),  date(Y,  9, 22))),\n",
    "                  ('autumn', (date(Y,  9, 23),  date(Y, 12, 20))),\n",
    "                  ('winter', (date(Y, 12, 21),  date(Y, 12, 31)))]\n",
    "        for season in seasons:\n",
    "            name = season[0]\n",
    "            start, end = season[1]\n",
    "            if (start.timetuple().tm_yday <= day <= end.timetuple().tm_yday):\n",
    "                return name\n",
    "        return None\n",
    "\n",
    "    def julian_to_datetime(self, jd_series):\n",
    "        # https://www.kaggle.com/rtatman/188-million-us-wildfires/discussion/39627#222290\n",
    "        epoch = pd.to_datetime(0, unit='s').to_julian_date()\n",
    "        return pd.to_datetime(jd_series - epoch, unit='D')\n",
    "\n",
    "    def difference_in_seconds(self):\n",
    "        start_times = self.df['DISCOVERY_TIME']\n",
    "        end_times = self.df['CONT_TIME']\n",
    "        return pd.to_datetime(end_times) - pd.to_datetime(start_times)\n",
    "\n",
    "    def num_to_time(self, num_time):\n",
    "        # num_time is in 24-hour format - so 0 to 2359\n",
    "        chars = list(str(int(num_time)))\n",
    "        res = []\n",
    "        for i in range(len(chars)-1, -1, -1):\n",
    "          res.append(chars[i])\n",
    "          if len(res) == 2:\n",
    "            res.append(\":\")\n",
    "        result = ''.join(res[::-1])\n",
    "        if len(result) == 1: result = \"00:0\" + result\n",
    "        if result[0] == \":\": result = \"00\" + result\n",
    "        return result\n",
    "    \n",
    "    def clean(self):\n",
    "        if self.cleaned: return\n",
    "        self.df = self.df.dropna(subset=WildfireClassifier.COLS)\n",
    "        self.df['CONT_TIME'] = self.df.apply(lambda row: self.num_to_time(row.CONT_TIME), axis=1)\n",
    "        self.df['DISCOVERY_TIME'] = self.df.apply(lambda row: self.num_to_time(row.DISCOVERY_TIME), axis=1)\n",
    "        self.df['CONT_DATE'] = self.df.apply(lambda row: self.julian_to_datetime(row.CONT_DATE), axis=1)\n",
    "        self.df['DISCOVERY_DATE'] = self.df.apply(lambda row: self.julian_to_datetime(row.DISCOVERY_DATE),axis=1)\n",
    "        self.df['season'] = self.df.apply(lambda row: self.get_season(row.DISCOVERY_DOY,self.year), axis=1)\n",
    "        self.df['natural_cause'] = self.df.apply(lambda row: row.STAT_CAUSE_DESCR == 'Lightning', axis=1)\n",
    "        full_disc_date = pd.to_datetime(self.df['DISCOVERY_DATE'].dt.strftime(\"%Y-%m-%d\") + ' ' + self.df['DISCOVERY_TIME'])\n",
    "        full_cont_date = pd.to_datetime(self.df['CONT_DATE'].dt.strftime(\"%Y-%m-%d\") + ' ' + self.df['CONT_TIME'])\n",
    "        self.df['duration'] = full_cont_date - full_disc_date\n",
    "\n",
    "        def get_region(state_code):\n",
    "            for region in WildfireClassifier.REGIONS:\n",
    "                if state_code in WildfireClassifier.REGIONS[region]: return region\n",
    "            print(state_code)\n",
    "            return None\n",
    "        self.df['region'] = self.df.apply(lambda row: get_region(row.STATE), axis=1)\n",
    "        \n",
    "        self.cleaned = True\n",
    "    \n",
    "    def test(self, train_frac):\n",
    "        label_names = [chr(ord('A') + i) for i in range(ord('G') - ord('A') + 1)]\n",
    "\n",
    "        def get_labels(fire_class):\n",
    "            if ord(fire_class) <= ord('C'):\n",
    "                return 0\n",
    "            if ord(fire_class) <= ord('F'):\n",
    "                return 1\n",
    "            return 2\n",
    "        # features: 'state', 'season', 'cause', 'duration' (maybe)\n",
    "        def extract_features(row):\n",
    "            regions_list = list(WildfireClassifier.REGIONS.keys())\n",
    "        #     duration_min = row.duration.days * 24 * 60 + row.duration.seconds//3600\n",
    "            return [WildfireClassifier.SEASONS.index(row.season), row.STAT_CAUSE_CODE, regions_list.index(row.region)]\n",
    "\n",
    "        feature_df = self.df[['FIRE_SIZE_CLASS','season', 'region', 'duration', 'STAT_CAUSE_CODE', 'natural_cause', 'STATE']]\n",
    "        \n",
    "        \n",
    "        X = [extract_features(row) for _,row in feature_df.iterrows()]\n",
    "        y = self.df['FIRE_SIZE_CLASS'].map(lambda fire_class: ord(fire_class) - ord('A'))\n",
    "        \n",
    "        # https://stackoverflow.com/a/4602224/8109239\n",
    "        def unison_shuffled_copies(a, b):\n",
    "            assert len(a) == len(b)\n",
    "            p = np.random.permutation(len(a))\n",
    "            return np.asarray(a)[p], np.asarray(b)[p]\n",
    "        X,y = unison_shuffled_copies(X,y)\n",
    "        \n",
    "        # Split data into training and test sets\n",
    "        TRAIN_SIZE = round(train_frac * len(X))\n",
    "        print(\"TRAIN_SIZE\", TRAIN_SIZE)\n",
    "        X_train, y_train = X[:TRAIN_SIZE], y[:TRAIN_SIZE]\n",
    "        X_test, y_test = X[TRAIN_SIZE:], y[TRAIN_SIZE:]\n",
    "\n",
    "        # Use naive bayes because features are independent of each other\n",
    "        from sklearn.naive_bayes import MultinomialNB\n",
    "        from sklearn import metrics\n",
    "        clf = MultinomialNB()\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(metrics.confusion_matrix(y_test, y_pred))\n",
    "        return metrics.accuracy_score(y_test,y_pred)\n",
    "    \n",
    "    def test2(self, train_frac):\n",
    "        label_names = [chr(ord('A') + i) for i in range(ord('G') - ord('A') + 1)]\n",
    "\n",
    "        def get_labels(fire_class):\n",
    "            if ord(fire_class) <= ord('C'):\n",
    "                return 0\n",
    "            if ord(fire_class) <= ord('F'):\n",
    "                return 1\n",
    "            return 2\n",
    "        # features: 'state', 'season', 'cause', 'duration' (maybe)\n",
    "        def extract_features(row):\n",
    "            regions_list = list(WildfireClassifier.REGIONS.keys())\n",
    "        #     duration_min = row.duration.days * 24 * 60 + row.duration.seconds//3600\n",
    "            return [WildfireClassifier.SEASONS.index(row.season), row.natural_cause, regions_list.index(row.region)]\n",
    "\n",
    "        feature_df = self.df[['FIRE_SIZE_CLASS','season', 'region', 'duration', 'STAT_CAUSE_CODE', 'natural_cause', 'STATE']]\n",
    "        \n",
    "        \n",
    "        X = [extract_features(row) for _,row in feature_df.iterrows()]\n",
    "        y = self.df['FIRE_SIZE_CLASS'].map(lambda fire_class: ord(fire_class) - ord('A'))\n",
    "        \n",
    "        # https://stackoverflow.com/a/4602224/8109239\n",
    "        def unison_shuffled_copies(a, b):\n",
    "            assert len(a) == len(b)\n",
    "            p = np.random.permutation(len(a))\n",
    "            return np.asarray(a)[p], np.asarray(b)[p]\n",
    "        X,y = unison_shuffled_copies(X,y)\n",
    "        \n",
    "        # Split data into training and test sets\n",
    "        TRAIN_SIZE = round(train_frac * len(X))\n",
    "        print(\"TRAIN_SIZE\", TRAIN_SIZE)\n",
    "        X_train, y_train = X[:TRAIN_SIZE], y[:TRAIN_SIZE]\n",
    "        X_test, y_test = X[TRAIN_SIZE:], y[TRAIN_SIZE:]\n",
    "\n",
    "        # Use naive bayes because features are independent of each other\n",
    "        from sklearn.naive_bayes import MultinomialNB\n",
    "        from sklearn import metrics\n",
    "        clf = MultinomialNB()\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(metrics.confusion_matrix(y_test, y_pred))\n",
    "        return metrics.accuracy_score(y_test,y_pred)\n",
    "\n",
    "    def test3(self, train_frac):\n",
    "        label_names = [chr(ord('A') + i) for i in range(ord('G') - ord('A') + 1)]\n",
    "\n",
    "        def get_labels(fire_class):\n",
    "            if ord(fire_class) <= ord('C'):\n",
    "                return 0\n",
    "            if ord(fire_class) <= ord('F'):\n",
    "                return 1\n",
    "            return 2\n",
    "        # features: 'state', 'season', 'cause', 'duration' (maybe)\n",
    "        def extract_features(row):\n",
    "            regions_list = list(WildfireClassifier.REGIONS.keys())\n",
    "        #     duration_min = row.duration.days * 24 * 60 + row.duration.seconds//3600\n",
    "            return [WildfireClassifier.SEASONS.index(row.season), row.STAT_CAUSE_CODE, regions_list.index(row.region)]\n",
    "\n",
    "        feature_df = self.df[['FIRE_SIZE_CLASS','season', 'region', 'duration', 'STAT_CAUSE_CODE', 'natural_cause', 'STATE']]\n",
    "        \n",
    "        \n",
    "        X = [extract_features(row) for _,row in feature_df.iterrows()]\n",
    "        y = self.df['FIRE_SIZE_CLASS'].map(get_labels)\n",
    "        \n",
    "        # https://stackoverflow.com/a/4602224/8109239\n",
    "        def unison_shuffled_copies(a, b):\n",
    "            assert len(a) == len(b)\n",
    "            p = np.random.permutation(len(a))\n",
    "            return np.asarray(a)[p], np.asarray(b)[p]\n",
    "        X,y = unison_shuffled_copies(X,y)\n",
    "        \n",
    "        # Split data into training and test sets\n",
    "        TRAIN_SIZE = round(train_frac * len(X))\n",
    "        print(\"TRAIN_SIZE\", TRAIN_SIZE)\n",
    "        X_train, y_train = X[:TRAIN_SIZE], y[:TRAIN_SIZE]\n",
    "        X_test, y_test = X[TRAIN_SIZE:], y[TRAIN_SIZE:]\n",
    "\n",
    "        # Use naive bayes because features are independent of each other\n",
    "        from sklearn.naive_bayes import MultinomialNB\n",
    "        from sklearn import metrics\n",
    "        clf = MultinomialNB()\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(metrics.confusion_matrix(y_test, y_pred))\n",
    "        self.get_cause_labels()\n",
    "        return metrics.accuracy_score(y_test,y_pred)\n",
    "    \n",
    "    def save_cleaned_data(self, path):\n",
    "        if not self.cleaned: self.clean()\n",
    "        df = self.df['season', 'region', 'STAT_CAUSE_CODE', 'duration']\n",
    "        df.to_csv(path, index=False)\n",
    "    \n",
    "    def get_cause_labels(self):\n",
    "        df = self.df[['STAT_CAUSE_CODE', 'STAT_CAUSE_DESCR']]\n",
    "        print(df.unique())\n",
    "    \n",
    "clf_1992 = WildfireClassifier('./wildfires_1992.csv', 2000)\n",
    "clf_1992.clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SIZE 21619\n",
      "[[4027 2068    0    0    0    0    0]\n",
      " [1862 4442    0    0    0    0    0]\n",
      " [ 369 1281    0    0    0    0    0]\n",
      " [  63  124    0    0    0    0    0]\n",
      " [  50   53    0    0    0    0    0]\n",
      " [  37   18    0    0    0    0    0]\n",
      " [  13    5    0    0    0    0    0]]\n",
      "0.587635303913\n"
     ]
    }
   ],
   "source": [
    "print(clf_1992.test(.6))\n",
    "# print(clf_1992.test2(.6))\n",
    "# print(clf_1992.test3(.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STAT_CAUSE_DESCR</th>\n",
       "      <th>STAT_CAUSE_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lightning</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Campfire</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Equipment Use</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Debris Burning</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Smoking</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Arson</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>Railroad</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>Children</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11452</th>\n",
       "      <td>Structure</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11483</th>\n",
       "      <td>Powerline</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11488</th>\n",
       "      <td>Fireworks</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16054</th>\n",
       "      <td>Missing/Undefined</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        STAT_CAUSE_DESCR  STAT_CAUSE_CODE\n",
       "0              Lightning              1.0\n",
       "2               Campfire              4.0\n",
       "16         Equipment Use              2.0\n",
       "21        Debris Burning              5.0\n",
       "23               Smoking              3.0\n",
       "24                 Arson              7.0\n",
       "96         Miscellaneous              9.0\n",
       "683             Railroad              6.0\n",
       "759             Children              8.0\n",
       "11452          Structure             12.0\n",
       "11483          Powerline             11.0\n",
       "11488          Fireworks             10.0\n",
       "16054  Missing/Undefined             13.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_1992.df[['STAT_CAUSE_DESCR','STAT_CAUSE_CODE']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (10,11,12,18,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (10,11,12,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (11,12,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (11,12,18,35,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (12,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (10,12,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (11,12,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "# for year in range(1992,2016):\n",
    "#     clf = WildfireClassifier('./wildfires_%d.csv' % year, year)\n",
    "#     with open(\"./csvsForClassification/trimmed_wildfires_%d.csv\" % year, \"w\") as csvtowrite:\n",
    "#         clf.save_cleaned_data(csvtowrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (9,11,12,13,14,15,16,17,18,19,36,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "with open('./wildfires.csv') as csvfile:\n",
    "    df = pd.read_csv(csvfile)\n",
    "    pairs = df[['STAT_CAUSE_DESCR','FIRE_SIZE_CLASS']].drop_duplicates()\n",
    "    res = []\n",
    "    for _, x in pairs.iterrows(): \n",
    "        cause, size_class = x['STAT_CAUSE_DESCR'], x['FIRE_SIZE_CLASS']\n",
    "        count = len(df[(df.STAT_CAUSE_DESCR==cause)&(df.FIRE_SIZE_CLASS==size_class)])\n",
    "        res.append([cause, size_class, count])\n",
    "    new_df = pd.DataFrame(data=res, columns=['cause','size_class','count'])\n",
    "    with open('./cause_to_size.csv', \"w\") as csvtowrite:\n",
    "        new_df.to_csv(csvtowrite, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (9,11,12,13,14,15,16,17,18,19,36,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "with open('./wildfires.csv') as csvfile:\n",
    "    df = pd.read_csv(csvfile)\n",
    "    pairs = df[['FIRE_SIZE_CLASS','STATE']].drop_duplicates()\n",
    "    res = []\n",
    "    for _, x in pairs.iterrows(): \n",
    "        size_class, state = x['FIRE_SIZE_CLASS'], x['STATE']\n",
    "        count = len(df[(df.FIRE_SIZE_CLASS==size_class)&(df.STATE==state)])\n",
    "        res.append([size_class, state, count])\n",
    "    new_df = pd.DataFrame(data=res, columns=['size_class','state','count'])\n",
    "    with open('./size_to_state.csv', \"w\") as csvtowrite:\n",
    "        new_df.to_csv(csvtowrite, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
