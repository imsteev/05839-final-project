{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = 1992\n",
    "COLS_NEEDED = [\n",
    "    \"FIRE_YEAR\",\n",
    "    \"DISCOVERY_DATE\",\n",
    "    \"DISCOVERY_DOY\",\n",
    "    \"DISCOVERY_TIME\",\n",
    "    \"STAT_CAUSE_CODE\",\n",
    "    \"STAT_CAUSE_DESCR\",\n",
    "    \"CONT_DATE\",\n",
    "    \"CONT_DOY\",\n",
    "    \"CONT_TIME\",\n",
    "    \"FIRE_SIZE\",\n",
    "    \"FIRE_SIZE_CLASS\",\n",
    "    \"LATITUDE\",\n",
    "    \"LONGITUDE\",\n",
    "    \"STATE\",\n",
    "    \"COUNTY\"\n",
    "]\n",
    "\n",
    "COLS_NEEDED_FOR_CLASSIFICATION = [\n",
    "    \"DISCOVERY_DATE\",\n",
    "    \"DISCOVERY_DOY\",\n",
    "    \"DISCOVERY_TIME\",\n",
    "    \"STAT_CAUSE_CODE\",\n",
    "    \"CONT_DATE\",\n",
    "    \"CONT_TIME\",\n",
    "    \"FIRE_SIZE_CLASS\",\n",
    "    \"STATE\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (10,11,12,18,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "with open('./wildfires_%d.csv' % YEAR) as csvfile:\n",
    "    df = pd.read_csv(csvfile)\n",
    "    df = df[COLS_NEEDED_FOR_CLASSIFICATION]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(day, Y):\n",
    "    seasons = [('winter', (date(Y,  1,  1),  date(Y,  3, 20))),\n",
    "              ('spring', (date(Y,  3, 21),  date(Y,  6, 20))),\n",
    "              ('summer', (date(Y,  6, 21),  date(Y,  9, 22))),\n",
    "              ('autumn', (date(Y,  9, 23),  date(Y, 12, 20))),\n",
    "              ('winter', (date(Y, 12, 21),  date(Y, 12, 31)))]\n",
    "    for season in seasons:\n",
    "        name = season[0]\n",
    "        start, end = season[1]\n",
    "        if (start.timetuple().tm_yday <= day <= end.timetuple().tm_yday):\n",
    "            return name\n",
    "    return None\n",
    "\n",
    "def julian_to_datetime(jd_series):\n",
    "    # https://www.kaggle.com/rtatman/188-million-us-wildfires/discussion/39627#222290\n",
    "    epoch = pd.to_datetime(0, unit='s').to_julian_date()\n",
    "    return pd.to_datetime(jd_series - epoch, unit='D')\n",
    "\n",
    "def difference_in_seconds():\n",
    "    start_times = df['DISCOVERY_TIME']\n",
    "    end_times = df['CONT_TIME']\n",
    "    return pd.to_datetime(end_times) - pd.to_datetime(start_times)\n",
    "\n",
    "def num_to_time(num_time):\n",
    "    # num_time is in 24-hour format - so 0 to 2359\n",
    "    chars = list(str(int(num_time)))\n",
    "    res = []\n",
    "    for i in range(len(chars)-1, -1, -1):\n",
    "      res.append(chars[i])\n",
    "      if len(res) == 2:\n",
    "        res.append(\":\")\n",
    "    result = ''.join(res[::-1])\n",
    "    if len(result) == 1: result = \"00:0\" + result\n",
    "    if result[0] == \":\": result = \"00\" + result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean\n",
    "df = df.dropna(subset=['CONT_DATE', 'DISCOVERY_DATE', 'CONT_TIME', 'DISCOVERY_TIME', 'DISCOVERY_DOY', 'STAT_CAUSE_CODE'])\n",
    "df['CONT_TIME'] = df.apply(lambda row: num_to_time(row.CONT_TIME), axis=1)\n",
    "df['DISCOVERY_TIME'] = df.apply(lambda row: num_to_time(row.DISCOVERY_TIME), axis=1)\n",
    "df['CONT_DATE'] = df.apply(lambda row: julian_to_datetime(row.CONT_DATE), axis=1)\n",
    "df['DISCOVERY_DATE'] = df.apply(lambda row: julian_to_datetime(row.DISCOVERY_DATE),axis=1)\n",
    "df['season'] = df.apply(lambda row: get_season(row.DISCOVERY_DOY,YEAR), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_disc_date = pd.to_datetime(df['DISCOVERY_DATE'].dt.strftime(\"%Y-%m-%d\") + ' ' + df['DISCOVERY_TIME'])\n",
    "full_cont_date = pd.to_datetime(df['CONT_DATE'].dt.strftime(\"%Y-%m-%d\") + ' ' + df['CONT_TIME'])\n",
    "df['duration'] = full_cont_date - full_disc_date\n",
    "\n",
    "# with open(\"./wildfires_dates.csv\", \"w\") as csvfile:\n",
    "#     df.to_csv(csvfile,\n",
    "#               index=False, \n",
    "#               columns=['FIRE_SIZE', 'DISCOVERY_DATE', 'LATITUDE', 'LONGITUDE', 'duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_STATE_CODES = ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'PR', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "\n",
    "# https://en.wikipedia.org/wiki/List_of_regions_of_the_United_States\n",
    "SEASONS = ['winter','spring','summer','autumn']\n",
    "STAT_CAUSE_CODES = list(range(1,14))\n",
    "\n",
    "REGIONS = {\n",
    "    'northeast': ['CT','ME','MA','NH','RI','VT','NJ','NY','PA'],\n",
    "    'midwest': ['IL','IN','MI','OH','WI','IA','KS','MN','MO','NE','ND','SD'],\n",
    "    'west': ['AZ','CO','ID','MT','NV','NM','UT','WY','AK','CA','HI','OR','WA'],\n",
    "    'south': ['DE','FL','GA','MD','NC','SC','VA','DC','WV','AL','KY','MS','TN','AR','LA','OK','TX', 'PR']\n",
    "}\n",
    "\n",
    "def get_region(state_code):\n",
    "    for region in REGIONS:\n",
    "        if state_code in REGIONS[region]: return region\n",
    "    print(state_code)\n",
    "    return None\n",
    "\n",
    "df['region'] = df.apply(lambda row: get_region(row.STATE), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create classifier\n",
    "# - extract features for each row\n",
    "# - create labels for each row (this should just be getting the fire class size and mapping it to an integer)\n",
    "# - split data into train + test sets (shuffle data first?)\n",
    "# - train data using a model (need to look this up)\n",
    "# - test for accuracy\n",
    "\n",
    "label_names = [chr(ord('A') + i) for i in range(ord('G') - ord('A') + 1)]\n",
    "\n",
    "# features: 'state', 'season', 'cause', 'duration' (maybe)\n",
    "\n",
    "def extract_features(row):\n",
    "    regions_list = list(REGIONS.keys())\n",
    "#     duration_min = row.duration.days * 24 * 60 + row.duration.seconds//3600\n",
    "    return [SEASONS.index(row.season), int(row.STAT_CAUSE_CODE), regions_list.index(row.region)]\n",
    "\n",
    "feature_df = df[['STAT_CAUSE_CODE', 'season', 'region', 'duration']]\n",
    "X = [extract_features(row) for _,row in feature_df.iterrows()]\n",
    "y = df['FIRE_SIZE_CLASS'].map(lambda fire_class: ord(fire_class) - ord('A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/4602224/8109239\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return np.asarray(a)[p], np.asarray(b)[p]\n",
    "\n",
    "X,y = unison_shuffled_copies(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.582755111481\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and test sets\n",
    "TRAIN_FRAC = 0.7\n",
    "TRAIN_SIZE = round(TRAIN_FRAC * len(X))\n",
    "X_train, y_train = X[:TRAIN_SIZE], y[:TRAIN_SIZE]\n",
    "X_test, y_test = X[TRAIN_SIZE:], y[TRAIN_SIZE:]\n",
    "\n",
    "# Use naive bayes because features are independent of each other\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save relevant data used for classification\n",
    "# for year in range(1992,2016):\n",
    "#     with open(\"./wildfires_%d.csv\" % year) as csvtoread:\n",
    "#         df = pd.read_csv(csvtoread)\n",
    "#         with open(\"./csvsForClassification/trimmed_wildfires_%d.csv\" % year, \"w\") as csvtowrite:\n",
    "#             df.to_csv(csvtowrite, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (10,11,12,18,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "class WildfireClassifier(object):\n",
    "    COLS = [\n",
    "        \"DISCOVERY_DATE\",\n",
    "        \"DISCOVERY_DOY\",\n",
    "        \"DISCOVERY_TIME\",\n",
    "        \"STAT_CAUSE_CODE\",\n",
    "        \"STAT_CAUSE_DESCR\",\n",
    "        \"CONT_DATE\",\n",
    "        \"CONT_TIME\",\n",
    "        \"FIRE_SIZE_CLASS\",\n",
    "        \"FIRE_SIZE\",\n",
    "        \"STATE\"\n",
    "    ]\n",
    "\n",
    "    REGIONS = {\n",
    "        'northeast': ['CT','ME','MA','NH','RI','VT','NJ','NY','PA'],\n",
    "        'midwest': ['IL','IN','MI','OH','WI','IA','KS','MN','MO','NE','ND','SD'],\n",
    "        'west': ['AZ','CO','ID','MT','NV','NM','UT','WY','AK','CA','HI','OR','WA'],\n",
    "        'south': ['DE','FL','GA','MD','NC','SC','VA','DC','WV','AL','KY','MS','TN','AR','LA','OK','TX', 'PR']\n",
    "    }\n",
    "    \n",
    "    US_STATE_CODES = ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'PR', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "    # https://en.wikipedia.org/wiki/List_of_regions_of_the_United_States\n",
    "    SEASONS = ['winter','spring','summer','autumn']\n",
    "    STAT_CAUSE_CODES = list(range(1,14))\n",
    "    \n",
    "    def __init__(self, fname, year):\n",
    "        self.cleaned = False\n",
    "        self.year = year\n",
    "        with open(fname) as csvfile:\n",
    "            self.df = pd.read_csv(csvfile)\n",
    "            self.df = self.df[WildfireClassifier.COLS]\n",
    "        \n",
    "#         for name, group in self.df.groupby('STAT_CAUSE_DESCR'):\n",
    "#             print(name, len(group))\n",
    "#         print(self.df[['FIRE_SIZE', 'FIRE_SIZE_CLASS']].drop_duplicates())\n",
    "            \n",
    "    def get_season(self, day, Y):\n",
    "        seasons = [('winter', (date(Y,  1,  1),  date(Y,  3, 20))),\n",
    "                  ('spring', (date(Y,  3, 21),  date(Y,  6, 20))),\n",
    "                  ('summer', (date(Y,  6, 21),  date(Y,  9, 22))),\n",
    "                  ('autumn', (date(Y,  9, 23),  date(Y, 12, 20))),\n",
    "                  ('winter', (date(Y, 12, 21),  date(Y, 12, 31)))]\n",
    "        for season in seasons:\n",
    "            name = season[0]\n",
    "            start, end = season[1]\n",
    "            if (start.timetuple().tm_yday <= day <= end.timetuple().tm_yday):\n",
    "                return name\n",
    "        return None\n",
    "\n",
    "    def julian_to_datetime(self, jd_series):\n",
    "        # https://www.kaggle.com/rtatman/188-million-us-wildfires/discussion/39627#222290\n",
    "        epoch = pd.to_datetime(0, unit='s').to_julian_date()\n",
    "        return pd.to_datetime(jd_series - epoch, unit='D')\n",
    "\n",
    "    def difference_in_seconds(self):\n",
    "        start_times = self.df['DISCOVERY_TIME']\n",
    "        end_times = self.df['CONT_TIME']\n",
    "        return pd.to_datetime(end_times) - pd.to_datetime(start_times)\n",
    "\n",
    "    def num_to_time(self, num_time):\n",
    "        # num_time is in 24-hour format - so 0 to 2359\n",
    "        chars = list(str(int(num_time)))\n",
    "        res = []\n",
    "        for i in range(len(chars)-1, -1, -1):\n",
    "          res.append(chars[i])\n",
    "          if len(res) == 2:\n",
    "            res.append(\":\")\n",
    "        result = ''.join(res[::-1])\n",
    "        if len(result) == 1: result = \"00:0\" + result\n",
    "        if result[0] == \":\": result = \"00\" + result\n",
    "        return result\n",
    "    \n",
    "    def clean(self):\n",
    "        if self.cleaned: return\n",
    "        self.df = self.df.dropna(subset=WildfireClassifier.COLS)\n",
    "        self.df['CONT_TIME'] = self.df.apply(lambda row: self.num_to_time(row.CONT_TIME), axis=1)\n",
    "        self.df['DISCOVERY_TIME'] = self.df.apply(lambda row: self.num_to_time(row.DISCOVERY_TIME), axis=1)\n",
    "        self.df['CONT_DATE'] = self.df.apply(lambda row: self.julian_to_datetime(row.CONT_DATE), axis=1)\n",
    "        self.df['DISCOVERY_DATE'] = self.df.apply(lambda row: self.julian_to_datetime(row.DISCOVERY_DATE),axis=1)\n",
    "        self.df['season'] = self.df.apply(lambda row: self.get_season(row.DISCOVERY_DOY,self.year), axis=1)\n",
    "        self.df['natural_cause'] = self.df.apply(lambda row: row.STAT_CAUSE_DESCR == 'Lightning', axis=1)\n",
    "        full_disc_date = pd.to_datetime(self.df['DISCOVERY_DATE'].dt.strftime(\"%Y-%m-%d\") + ' ' + self.df['DISCOVERY_TIME'])\n",
    "        full_cont_date = pd.to_datetime(self.df['CONT_DATE'].dt.strftime(\"%Y-%m-%d\") + ' ' + self.df['CONT_TIME'])\n",
    "        self.df['duration'] = full_cont_date - full_disc_date\n",
    "\n",
    "        def get_region(state_code):\n",
    "            for region in WildfireClassifier.REGIONS:\n",
    "                if state_code in WildfireClassifier.REGIONS[region]: return region\n",
    "            print(state_code)\n",
    "            return None\n",
    "        self.df['region'] = self.df.apply(lambda row: get_region(row.STATE), axis=1)\n",
    "        \n",
    "        self.cleaned = True\n",
    "    \n",
    "    def test(self, train_frac):\n",
    "        label_names = [chr(ord('A') + i) for i in range(ord('G') - ord('A') + 1)]\n",
    "\n",
    "        def get_labels(fire_class):\n",
    "            if ord(fire_class) <= ord('C'):\n",
    "                return 0\n",
    "            if ord(fire_class) <= ord('F'):\n",
    "                return 1\n",
    "            return 2\n",
    "        # features: 'state', 'season', 'cause', 'duration' (maybe)\n",
    "        def extract_features(row):\n",
    "            regions_list = list(WildfireClassifier.REGIONS.keys())\n",
    "        #     duration_min = row.duration.days * 24 * 60 + row.duration.seconds//3600\n",
    "            return [WildfireClassifier.SEASONS.index(row.season), row.STAT_CAUSE_CODE, regions_list.index(row.region)]\n",
    "\n",
    "        feature_df = self.df[['FIRE_SIZE_CLASS','season', 'region', 'duration', 'STAT_CAUSE_CODE', 'natural_cause', 'STATE']]\n",
    "        \n",
    "        \n",
    "        X = [extract_features(row) for _,row in feature_df.iterrows()]\n",
    "        y = self.df['FIRE_SIZE_CLASS'].map(lambda fire_class: ord(fire_class) - ord('A'))\n",
    "        \n",
    "        # https://stackoverflow.com/a/4602224/8109239\n",
    "        def unison_shuffled_copies(a, b):\n",
    "            assert len(a) == len(b)\n",
    "            p = np.random.permutation(len(a))\n",
    "            return np.asarray(a)[p], np.asarray(b)[p]\n",
    "        X,y = unison_shuffled_copies(X,y)\n",
    "        \n",
    "        # Split data into training and test sets\n",
    "        TRAIN_SIZE = round(train_frac * len(X))\n",
    "        print(\"TRAIN_SIZE\", TRAIN_SIZE)\n",
    "        X_train, y_train = X[:TRAIN_SIZE], y[:TRAIN_SIZE]\n",
    "        X_test, y_test = X[TRAIN_SIZE:], y[TRAIN_SIZE:]\n",
    "\n",
    "        # Use naive bayes because features are independent of each other\n",
    "        from sklearn.naive_bayes import MultinomialNB\n",
    "        from sklearn import metrics\n",
    "        clf = MultinomialNB()\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(metrics.confusion_matrix(y_test, y_pred))\n",
    "        return metrics.accuracy_score(y_test,y_pred)\n",
    "    \n",
    "    def test2(self, train_frac):\n",
    "        label_names = [chr(ord('A') + i) for i in range(ord('G') - ord('A') + 1)]\n",
    "\n",
    "        def get_labels(fire_class):\n",
    "            if ord(fire_class) <= ord('C'):\n",
    "                return 0\n",
    "            if ord(fire_class) <= ord('F'):\n",
    "                return 1\n",
    "            return 2\n",
    "        # features: 'state', 'season', 'cause', 'duration' (maybe)\n",
    "        def extract_features(row):\n",
    "            regions_list = list(WildfireClassifier.REGIONS.keys())\n",
    "        #     duration_min = row.duration.days * 24 * 60 + row.duration.seconds//3600\n",
    "            return [WildfireClassifier.SEASONS.index(row.season), row.natural_cause, regions_list.index(row.region)]\n",
    "\n",
    "        feature_df = self.df[['FIRE_SIZE_CLASS','season', 'region', 'duration', 'STAT_CAUSE_CODE', 'natural_cause', 'STATE']]\n",
    "        \n",
    "        \n",
    "        X = [extract_features(row) for _,row in feature_df.iterrows()]\n",
    "        y = self.df['FIRE_SIZE_CLASS'].map(lambda fire_class: ord(fire_class) - ord('A'))\n",
    "        \n",
    "        # https://stackoverflow.com/a/4602224/8109239\n",
    "        def unison_shuffled_copies(a, b):\n",
    "            assert len(a) == len(b)\n",
    "            p = np.random.permutation(len(a))\n",
    "            return np.asarray(a)[p], np.asarray(b)[p]\n",
    "        X,y = unison_shuffled_copies(X,y)\n",
    "        \n",
    "        # Split data into training and test sets\n",
    "        TRAIN_SIZE = round(train_frac * len(X))\n",
    "        print(\"TRAIN_SIZE\", TRAIN_SIZE)\n",
    "        X_train, y_train = X[:TRAIN_SIZE], y[:TRAIN_SIZE]\n",
    "        X_test, y_test = X[TRAIN_SIZE:], y[TRAIN_SIZE:]\n",
    "\n",
    "        # Use naive bayes because features are independent of each other\n",
    "        from sklearn.naive_bayes import MultinomialNB\n",
    "        from sklearn import metrics\n",
    "        clf = MultinomialNB()\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(metrics.confusion_matrix(y_test, y_pred))\n",
    "        return metrics.accuracy_score(y_test,y_pred)\n",
    "\n",
    "    def test3(self, train_frac):\n",
    "        label_names = [chr(ord('A') + i) for i in range(ord('G') - ord('A') + 1)]\n",
    "\n",
    "        def get_labels(fire_class):\n",
    "            if ord(fire_class) <= ord('C'):\n",
    "                return 0\n",
    "            if ord(fire_class) <= ord('F'):\n",
    "                return 1\n",
    "            return 2\n",
    "        # features: 'state', 'season', 'cause', 'duration' (maybe)\n",
    "        def extract_features(row):\n",
    "            regions_list = list(WildfireClassifier.REGIONS.keys())\n",
    "        #     duration_min = row.duration.days * 24 * 60 + row.duration.seconds//3600\n",
    "            return [WildfireClassifier.SEASONS.index(row.season), row.STAT_CAUSE_CODE, regions_list.index(row.region)]\n",
    "\n",
    "        feature_df = self.df[['FIRE_SIZE_CLASS','season', 'region', 'duration', 'STAT_CAUSE_CODE', 'natural_cause', 'STATE']]\n",
    "        \n",
    "        \n",
    "        X = [extract_features(row) for _,row in feature_df.iterrows()]\n",
    "        y = self.df['FIRE_SIZE_CLASS'].map(get_labels)\n",
    "        \n",
    "        # https://stackoverflow.com/a/4602224/8109239\n",
    "        def unison_shuffled_copies(a, b):\n",
    "            assert len(a) == len(b)\n",
    "            p = np.random.permutation(len(a))\n",
    "            return np.asarray(a)[p], np.asarray(b)[p]\n",
    "        X,y = unison_shuffled_copies(X,y)\n",
    "        \n",
    "        # Split data into training and test sets\n",
    "        TRAIN_SIZE = round(train_frac * len(X))\n",
    "        print(\"TRAIN_SIZE\", TRAIN_SIZE)\n",
    "        X_train, y_train = X[:TRAIN_SIZE], y[:TRAIN_SIZE]\n",
    "        X_test, y_test = X[TRAIN_SIZE:], y[TRAIN_SIZE:]\n",
    "\n",
    "        # Use naive bayes because features are independent of each other\n",
    "        from sklearn.naive_bayes import MultinomialNB\n",
    "        from sklearn import metrics\n",
    "        clf = MultinomialNB()\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(metrics.confusion_matrix(y_test, y_pred))\n",
    "        self.get_cause_labels()\n",
    "        return metrics.accuracy_score(y_test,y_pred)\n",
    "    \n",
    "    def save_cleaned_data(self, path):\n",
    "        if not self.cleaned: self.clean()\n",
    "        df = self.df['season', 'region', 'STAT_CAUSE_CODE', 'duration']\n",
    "        df.to_csv(path, index=False)\n",
    "    \n",
    "    def get_cause_labels(self):\n",
    "        df = self.df[['STAT_CAUSE_CODE', 'STAT_CAUSE_DESCR']]\n",
    "        print(df.unique())\n",
    "    \n",
    "clf_1992 = WildfireClassifier('./wildfires_1992.csv', 2000)\n",
    "clf_1992.clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SIZE 21619\n",
      "[[4027 2068    0    0    0    0    0]\n",
      " [1862 4442    0    0    0    0    0]\n",
      " [ 369 1281    0    0    0    0    0]\n",
      " [  63  124    0    0    0    0    0]\n",
      " [  50   53    0    0    0    0    0]\n",
      " [  37   18    0    0    0    0    0]\n",
      " [  13    5    0    0    0    0    0]]\n",
      "0.587635303913\n"
     ]
    }
   ],
   "source": [
    "print(clf_1992.test(.6))\n",
    "# print(clf_1992.test2(.6))\n",
    "# print(clf_1992.test3(.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STAT_CAUSE_DESCR</th>\n",
       "      <th>STAT_CAUSE_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lightning</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Campfire</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Equipment Use</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Debris Burning</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Smoking</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Arson</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>Railroad</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>Children</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11452</th>\n",
       "      <td>Structure</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11483</th>\n",
       "      <td>Powerline</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11488</th>\n",
       "      <td>Fireworks</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16054</th>\n",
       "      <td>Missing/Undefined</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        STAT_CAUSE_DESCR  STAT_CAUSE_CODE\n",
       "0              Lightning              1.0\n",
       "2               Campfire              4.0\n",
       "16         Equipment Use              2.0\n",
       "21        Debris Burning              5.0\n",
       "23               Smoking              3.0\n",
       "24                 Arson              7.0\n",
       "96         Miscellaneous              9.0\n",
       "683             Railroad              6.0\n",
       "759             Children              8.0\n",
       "11452          Structure             12.0\n",
       "11483          Powerline             11.0\n",
       "11488          Fireworks             10.0\n",
       "16054  Missing/Undefined             13.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_1992.df[['STAT_CAUSE_DESCR','STAT_CAUSE_CODE']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (10,11,12,18,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SIZE 28825\n",
      "[[2018  928    0    0    0    0    0]\n",
      " [ 994 2253    0    0    0    0    0]\n",
      " [ 198  634    0    0    0    0    0]\n",
      " [  39   57    0    0    0    0    0]\n",
      " [  26   24    0    0    0    0    0]\n",
      " [  14   14    0    0    0    0    0]\n",
      " [   5    2    0    0    0    0    0]]\n",
      "1992 0.592700527338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (10,11,12,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SIZE 26813\n",
      "[[ 853 1535    0    0    0    0    0]\n",
      " [ 606 2711    0    0    0    0    0]\n",
      " [ 106  693    0    0    0    0    0]\n",
      " [  17   75    0    0    0    0    0]\n",
      " [  14   51    0    0    0    0    0]\n",
      " [  13   20    0    0    0    0    0]\n",
      " [   3    6    0    0    0    0    0]]\n",
      "1993 0.531702222885\n",
      "TRAIN_SIZE 32772\n",
      "[[2242 1144    0    0    0    0    0]\n",
      " [1299 2297    0    0    0    0    0]\n",
      " [ 285  633    0    0    0    0    0]\n",
      " [  67   60    0    0    0    0    0]\n",
      " [  44   26    0    0    0    0    0]\n",
      " [  49   11    0    0    0    0    0]\n",
      " [  32    4    0    0    0    0    0]]\n",
      "1994 0.554009520322\n",
      "TRAIN_SIZE 29474\n",
      "[[1124 1461    0    0    0    0    0]\n",
      " [ 843 2753    0    0    0    0    0]\n",
      " [ 204  757    0    0    0    0    0]\n",
      " [  32   74    0    0    0    0    0]\n",
      " [  28   39    0    0    0    0    0]\n",
      " [  20   21    0    0    0    0    0]\n",
      " [  10    3    0    0    0    0    0]]\n",
      "1995 0.526122947483\n",
      "TRAIN_SIZE 33466\n",
      "[[1998 1212    0    0    0    0    0]\n",
      " [1190 2636    0    0    0    0    0]\n",
      " [ 230  758    0    0    0    0    0]\n",
      " [  57  107    0    0    0    0    0]\n",
      " [  44   53    0    0    0    0    0]\n",
      " [  31   20    0    0    0    0    0]\n",
      " [  23    8    0    0    0    0    0]]\n",
      "1996 0.553842476395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (11,12,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SIZE 20697\n",
      "[[1396  776    0    0    0    0    0]\n",
      " [ 911 1533    0    0    0    0    0]\n",
      " [ 180  281    0    0    0    0    0]\n",
      " [  35   24    0    0    0    0    0]\n",
      " [  12    9    0    0    0    0    0]\n",
      " [   7    4    0    0    0    0    0]\n",
      " [   4    2    0    0    0    0    0]]\n",
      "1997 0.566099729416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (11,12,18,35,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SIZE 19427\n",
      "[[1432  703    0    0    0    0    0]\n",
      " [ 879 1151    0    0    0    0    0]\n",
      " [ 231  304    0    0    0    0    0]\n",
      " [  35   41    0    0    0    0    0]\n",
      " [  26   14    0    0    0    0    0]\n",
      " [  20   11    0    0    0    0    0]\n",
      " [   6    4    0    0    0    0    0]]\n",
      "1998 0.531809759111\n",
      "TRAIN_SIZE 23589\n",
      "[[1564  894    0    0    0    0    0]\n",
      " [1046 1440    0    0    0    0    0]\n",
      " [ 273  411    0    0    0    0    0]\n",
      " [  57   59    0    0    0    0    0]\n",
      " [  44   29    0    0    0    0    0]\n",
      " [  37   18    0    0    0    0    0]\n",
      " [  22    3    0    0    0    0    0]]\n",
      "1999 0.509411565203\n",
      "TRAIN_SIZE 30087\n",
      "[[1982 1324    0    0    0    0    0]\n",
      " [1300 2005    0    0    0    0    0]\n",
      " [ 235  400    0    0    0    0    0]\n",
      " [  62   49    0    0    0    0    0]\n",
      " [  46   29    0    0    0    0    0]\n",
      " [  38   11    0    0    0    0    0]\n",
      " [  35    6    0    0    0    0    0]]\n",
      "2000 0.530045200744\n",
      "TRAIN_SIZE 29607\n",
      "[[2123 1228    0    0    0    0    0]\n",
      " [1476 1841    0    0    0    0    0]\n",
      " [ 235  271    0    0    0    0    0]\n",
      " [  66   35    0    0    0    0    0]\n",
      " [  40   26    0    0    0    0    0]\n",
      " [  30   10    0    0    0    0    0]\n",
      " [  16    5    0    0    0    0    0]]\n",
      "2001 0.535530937584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SIZE 28286\n",
      "[[1914 1264    0    0    0    0    0]\n",
      " [1141 1987    0    0    0    0    0]\n",
      " [ 209  342    0    0    0    0    0]\n",
      " [  36   70    0    0    0    0    0]\n",
      " [  26   18    0    0    0    0    0]\n",
      " [  23   14    0    0    0    0    0]\n",
      " [  20    8    0    0    0    0    0]]\n",
      "2002 0.55161199095\n",
      "TRAIN_SIZE 25471\n",
      "[[2354  944    0    0    0    0    0]\n",
      " [1190 1160    0    0    0    0    0]\n",
      " [ 274  225    0    0    0    0    0]\n",
      " [  59   48    0    0    0    0    0]\n",
      " [  37   16    0    0    0    0    0]\n",
      " [  27   11    0    0    0    0    0]\n",
      " [  21    2    0    0    0    0    0]]\n",
      "2003 0.55182160804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (12,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SIZE 22231\n",
      "[[2233  721    0    0    0    0    0]\n",
      " [1043  957    0    0    0    0    0]\n",
      " [ 200  277    0    0    0    0    0]\n",
      " [  30   30    0    0    0    0    0]\n",
      " [  24   10    0    0    0    0    0]\n",
      " [  15    4    0    0    0    0    0]\n",
      " [  12    2    0    0    0    0    0]]\n",
      "2004 0.573947463116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (10,12,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SIZE 26642\n",
      "[[2564  495    0    0    0    0    0]\n",
      " [1714  936    0    0    0    0    0]\n",
      " [ 326  322    0    0    0    0    0]\n",
      " [  76   43    0    0    0    0    0]\n",
      " [  50   28    0    0    0    0    0]\n",
      " [  56   15    0    0    0    0    0]\n",
      " [  32    3    0    0    0    0    0]]\n",
      "2005 0.525525525526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (11,12,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SIZE 30328\n",
      "[[2258 1184    0    0    0    0    0]\n",
      " [1377 1599    0    0    0    0    0]\n",
      " [ 394  409    0    0    0    0    0]\n",
      " [  81   68    0    0    0    0    0]\n",
      " [  54   35    0    0    0    0    0]\n",
      " [  60   16    0    0    0    0    0]\n",
      " [  36   11    0    0    0    0    0]]\n",
      "2006 0.508704827222\n",
      "TRAIN_SIZE 28488\n",
      "[[2647  637    0    0    0    0    0]\n",
      " [1837  982    0    0    0    0    0]\n",
      " [ 314  382    0    0    0    0    0]\n",
      " [  67   75    0    0    0    0    0]\n",
      " [  56   30    0    0    0    0    0]\n",
      " [  39   16    0    0    0    0    0]\n",
      " [  37    3    0    0    0    0    0]]\n",
      "2007 0.509547879809\n",
      "TRAIN_SIZE 23106\n",
      "[[1880  729    0    0    0    0    0]\n",
      " [1205 1154    0    0    0    0    0]\n",
      " [ 260  293    0    0    0    0    0]\n",
      " [  72   56    0    0    0    0    0]\n",
      " [  43   24    0    0    0    0    0]\n",
      " [  29   13    0    0    0    0    0]\n",
      " [  15    3    0    0    0    0    0]]\n",
      "2008 0.52527700831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SIZE 26587\n",
      "[[2197  786    0    0    0    0    0]\n",
      " [1272 1378    0    0    0    0    0]\n",
      " [ 270  435    0    0    0    0    0]\n",
      " [  65   83    0    0    0    0    0]\n",
      " [  45   46    0    0    0    0    0]\n",
      " [  29   22    0    0    0    0    0]\n",
      " [  16    3    0    0    0    0    0]]\n",
      "2009 0.537836618023\n",
      "TRAIN_SIZE 23578\n",
      "[[1243 1171    0    0    0    0    0]\n",
      " [ 874 1591    0    0    0    0    0]\n",
      " [ 272  472    0    0    0    0    0]\n",
      " [  70   75    0    0    0    0    0]\n",
      " [  30   43    0    0    0    0    0]\n",
      " [  18   19    0    0    0    0    0]\n",
      " [  15    2    0    0    0    0    0]]\n",
      "2010 0.48074639525\n",
      "TRAIN_SIZE 46797\n",
      "[[1020 2976    0    0    0    0    0]\n",
      " [ 535 5159    0    0    0    0    0]\n",
      " [  97 1349    0    0    0    0    0]\n",
      " [  16  251    0    0    0    0    0]\n",
      " [   6  137    0    0    0    0    0]\n",
      " [  12   97    0    0    0    0    0]\n",
      " [   3   41    0    0    0    0    0]]\n",
      "2011 0.52816480041\n",
      "TRAIN_SIZE 40771\n",
      "[[1380 2781    0    0    0    0    0]\n",
      " [ 957 3554    0    0    0    0    0]\n",
      " [ 180  955    0    0    0    0    0]\n",
      " [  34  139    0    0    0    0    0]\n",
      " [  23   74    0    0    0    0    0]\n",
      " [  14   60    0    0    0    0    0]\n",
      " [   8   34    0    0    0    0    0]]\n",
      "2012 0.484057686648\n",
      "TRAIN_SIZE 36222\n",
      "[[3173 1081    0    0    0    0    0]\n",
      " [2171 1680    0    0    0    0    0]\n",
      " [ 348  380    0    0    0    0    0]\n",
      " [  68   34    0    0    0    0    0]\n",
      " [  37   20    0    0    0    0    0]\n",
      " [  32    9    0    0    0    0    0]\n",
      " [  21    1    0    0    0    0    0]]\n",
      "2013 0.535946990613\n",
      "TRAIN_SIZE 38250\n",
      "[[2564 1464    0    0    0    0    0]\n",
      " [1793 2544    0    0    0    0    0]\n",
      " [ 289  681    0    0    0    0    0]\n",
      " [  53   63    0    0    0    0    0]\n",
      " [  27   38    0    0    0    0    0]\n",
      " [  20   10    0    0    0    0    0]\n",
      " [  12    4    0    0    0    0    0]]\n",
      "2014 0.534197866555\n",
      "TRAIN_SIZE 42091\n",
      "[[2419 2125    0    0    0    0    0]\n",
      " [1781 2755    0    0    0    0    0]\n",
      " [ 350  779    0    0    0    0    0]\n",
      " [  57   91    0    0    0    0    0]\n",
      " [  21   57    0    0    0    0    0]\n",
      " [   8   37    0    0    0    0    0]\n",
      " [   4   39    0    0    0    0    0]]\n",
      "2015 0.491684880737\n"
     ]
    }
   ],
   "source": [
    "for year in range(1992,2016):\n",
    "    clf = WildfireClassifier('./wildfires_%d.csv' % year, year)\n",
    "#     clf.train()\n",
    "    clf.clean()\n",
    "    print(year, clf.test(0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (9,11,12,13,14,15,16,17,18,19,36,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "with open('./wildfires.csv') as csvfile:\n",
    "    df = pd.read_csv(csvfile)\n",
    "    pairs = df[['STAT_CAUSE_DESCR','FIRE_SIZE_CLASS']].drop_duplicates()\n",
    "    res = []\n",
    "    for _, x in pairs.iterrows(): \n",
    "        cause, size_class = x['STAT_CAUSE_DESCR'], x['FIRE_SIZE_CLASS']\n",
    "        count = len(df[(df.STAT_CAUSE_DESCR==cause)&(df.FIRE_SIZE_CLASS==size_class)])\n",
    "        res.append([cause, size_class, count])\n",
    "    new_df = pd.DataFrame(data=res, columns=['cause','size_class','count'])\n",
    "    with open('./cause_to_size.csv', \"w\") as csvtowrite:\n",
    "        new_df.to_csv(csvtowrite, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (9,11,12,13,14,15,16,17,18,19,36,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "with open('./wildfires.csv') as csvfile:\n",
    "    df = pd.read_csv(csvfile)\n",
    "    pairs = df[['FIRE_SIZE_CLASS','STATE']].drop_duplicates()\n",
    "    res = []\n",
    "    for _, x in pairs.iterrows(): \n",
    "        size_class, state = x['FIRE_SIZE_CLASS'], x['STATE']\n",
    "        count = len(df[(df.FIRE_SIZE_CLASS==size_class)&(df.STATE==state)])\n",
    "        res.append([size_class, state, count])\n",
    "    new_df = pd.DataFrame(data=res, columns=['size_class','state','count'])\n",
    "    with open('./size_to_state.csv', \"w\") as csvtowrite:\n",
    "        new_df.to_csv(csvtowrite, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
