{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = 1992\n",
    "COLS_NEEDED = [\n",
    "    \"FIRE_YEAR\",\n",
    "    \"DISCOVERY_DATE\",\n",
    "    \"DISCOVERY_DOY\",\n",
    "    \"DISCOVERY_TIME\",\n",
    "    \"STAT_CAUSE_CODE\",\n",
    "    \"STAT_CAUSE_DESCR\",\n",
    "    \"CONT_DATE\",\n",
    "    \"CONT_DOY\",\n",
    "    \"CONT_TIME\",\n",
    "    \"FIRE_SIZE\",\n",
    "    \"FIRE_SIZE_CLASS\",\n",
    "    \"LATITUDE\",\n",
    "    \"LONGITUDE\",\n",
    "    \"STATE\",\n",
    "    \"COUNTY\"\n",
    "]\n",
    "\n",
    "COLS_NEEDED_FOR_CLASSIFICATION = [\n",
    "    \"DISCOVERY_DATE\",\n",
    "    \"DISCOVERY_DOY\",\n",
    "    \"DISCOVERY_TIME\",\n",
    "    \"STAT_CAUSE_CODE\",\n",
    "    \"CONT_DATE\",\n",
    "    \"CONT_TIME\",\n",
    "    \"FIRE_SIZE_CLASS\",\n",
    "    \"STATE\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (10,11,12,18,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "with open('./wildfires_%d.csv' % YEAR) as csvfile:\n",
    "    df = pd.read_csv(csvfile)\n",
    "    df = df[COLS_NEEDED_FOR_CLASSIFICATION]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(day, Y):\n",
    "    seasons = [('winter', (date(Y,  1,  1),  date(Y,  3, 20))),\n",
    "              ('spring', (date(Y,  3, 21),  date(Y,  6, 20))),\n",
    "              ('summer', (date(Y,  6, 21),  date(Y,  9, 22))),\n",
    "              ('autumn', (date(Y,  9, 23),  date(Y, 12, 20))),\n",
    "              ('winter', (date(Y, 12, 21),  date(Y, 12, 31)))]\n",
    "    for season in seasons:\n",
    "        name = season[0]\n",
    "        start, end = season[1]\n",
    "        if (start.timetuple().tm_yday <= day <= end.timetuple().tm_yday):\n",
    "            return name\n",
    "    return None\n",
    "\n",
    "def julian_to_datetime(jd_series):\n",
    "    # https://www.kaggle.com/rtatman/188-million-us-wildfires/discussion/39627#222290\n",
    "    epoch = pd.to_datetime(0, unit='s').to_julian_date()\n",
    "    return pd.to_datetime(jd_series - epoch, unit='D')\n",
    "\n",
    "def difference_in_seconds():\n",
    "    start_times = df['DISCOVERY_TIME']\n",
    "    end_times = df['CONT_TIME']\n",
    "    return pd.to_datetime(end_times) - pd.to_datetime(start_times)\n",
    "\n",
    "def num_to_time(num_time):\n",
    "    # num_time is in 24-hour format - so 0 to 2359\n",
    "    chars = list(str(int(num_time)))\n",
    "    res = []\n",
    "    for i in range(len(chars)-1, -1, -1):\n",
    "      res.append(chars[i])\n",
    "      if len(res) == 2:\n",
    "        res.append(\":\")\n",
    "    result = ''.join(res[::-1])\n",
    "    if len(result) == 1: result = \"00:0\" + result\n",
    "    if result[0] == \":\": result = \"00\" + result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean\n",
    "df = df.dropna(subset=['CONT_DATE', 'DISCOVERY_DATE', 'CONT_TIME', 'DISCOVERY_TIME', 'DISCOVERY_DOY', 'STAT_CAUSE_CODE'])\n",
    "df['CONT_TIME'] = df.apply(lambda row: num_to_time(row.CONT_TIME), axis=1)\n",
    "df['DISCOVERY_TIME'] = df.apply(lambda row: num_to_time(row.DISCOVERY_TIME), axis=1)\n",
    "df['CONT_DATE'] = df.apply(lambda row: julian_to_datetime(row.CONT_DATE), axis=1)\n",
    "df['DISCOVERY_DATE'] = df.apply(lambda row: julian_to_datetime(row.DISCOVERY_DATE),axis=1)\n",
    "df['season'] = df.apply(lambda row: get_season(row.DISCOVERY_DOY,YEAR), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_disc_date = pd.to_datetime(df['DISCOVERY_DATE'].dt.strftime(\"%Y-%m-%d\") + ' ' + df['DISCOVERY_TIME'])\n",
    "full_cont_date = pd.to_datetime(df['CONT_DATE'].dt.strftime(\"%Y-%m-%d\") + ' ' + df['CONT_TIME'])\n",
    "df['duration'] = full_cont_date - full_disc_date\n",
    "\n",
    "# with open(\"./wildfires_dates.csv\", \"w\") as csvfile:\n",
    "#     df.to_csv(csvfile,\n",
    "#               index=False, \n",
    "#               columns=['FIRE_SIZE', 'DISCOVERY_DATE', 'LATITUDE', 'LONGITUDE', 'duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_STATE_CODES = ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'PR', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "\n",
    "# https://en.wikipedia.org/wiki/List_of_regions_of_the_United_States\n",
    "SEASONS = ['winter','spring','summer','autumn']\n",
    "STAT_CAUSE_CODES = list(range(1,14))\n",
    "\n",
    "REGIONS = {\n",
    "    'northeast': ['CT','ME','MA','NH','RI','VT','NJ','NY','PA'],\n",
    "    'midwest': ['IL','IN','MI','OH','WI','IA','KS','MN','MO','NE','ND','SD'],\n",
    "    'west': ['AZ','CO','ID','MT','NV','NM','UT','WY','AK','CA','HI','OR','WA'],\n",
    "    'south': ['DE','FL','GA','MD','NC','SC','VA','DC','WV','AL','KY','MS','TN','AR','LA','OK','TX', 'PR']\n",
    "}\n",
    "\n",
    "def get_region(state_code):\n",
    "    for region in REGIONS:\n",
    "        if state_code in REGIONS[region]: return region\n",
    "    print(state_code)\n",
    "    return None\n",
    "\n",
    "df['region'] = df.apply(lambda row: get_region(row.STATE), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create classifier\n",
    "# - extract features for each row\n",
    "# - create labels for each row (this should just be getting the fire class size and mapping it to an integer)\n",
    "# - split data into train + test sets (shuffle data first?)\n",
    "# - train data using a model (need to look this up)\n",
    "# - test for accuracy\n",
    "\n",
    "label_names = [chr(ord('A') + i) for i in range(ord('G') - ord('A') + 1)]\n",
    "\n",
    "# features: 'state', 'season', 'cause', 'duration' (maybe)\n",
    "\n",
    "def extract_features(row):\n",
    "    regions_list = list(REGIONS.keys())\n",
    "#     duration_min = row.duration.days * 24 * 60 + row.duration.seconds//3600\n",
    "    return [SEASONS.index(row.season), int(row.STAT_CAUSE_CODE), regions_list.index(row.region)]\n",
    "\n",
    "feature_df = df[['STAT_CAUSE_CODE', 'season', 'region', 'duration']]\n",
    "X = [extract_features(row) for _,row in feature_df.iterrows()]\n",
    "y = df['FIRE_SIZE_CLASS'].map(lambda fire_class: ord(fire_class) - ord('A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/4602224/8109239\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return np.asarray(a)[p], np.asarray(b)[p]\n",
    "\n",
    "X,y = unison_shuffled_copies(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.582755111481\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and test sets\n",
    "TRAIN_FRAC = 0.7\n",
    "TRAIN_SIZE = round(TRAIN_FRAC * len(X))\n",
    "X_train, y_train = X[:TRAIN_SIZE], y[:TRAIN_SIZE]\n",
    "X_test, y_test = X[TRAIN_SIZE:], y[TRAIN_SIZE:]\n",
    "\n",
    "# Use naive bayes because features are independent of each other\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save relevant data used for classification\n",
    "# for year in range(1992,2016):\n",
    "#     with open(\"./wildfires_%d.csv\" % year) as csvtoread:\n",
    "#         df = pd.read_csv(csvtoread)\n",
    "#         with open(\"./csvsForClassification/trimmed_wildfires_%d.csv\" % year, \"w\") as csvtowrite:\n",
    "#             df.to_csv(csvtowrite, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (10,11,12,18,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "class WildfireClassifier(object):\n",
    "    COLS = [\n",
    "        \"DISCOVERY_DATE\",\n",
    "        \"DISCOVERY_DOY\",\n",
    "        \"DISCOVERY_TIME\",\n",
    "        \"STAT_CAUSE_CODE\",\n",
    "        \"STAT_CAUSE_DESCR\",\n",
    "        \"CONT_DATE\",\n",
    "        \"CONT_TIME\",\n",
    "        \"FIRE_SIZE_CLASS\",\n",
    "        \"FIRE_SIZE\",\n",
    "        \"STATE\"\n",
    "    ]\n",
    "\n",
    "    REGIONS = {\n",
    "        'northeast': ['CT','ME','MA','NH','RI','VT','NJ','NY','PA'],\n",
    "        'midwest': ['IL','IN','MI','OH','WI','IA','KS','MN','MO','NE','ND','SD'],\n",
    "        'west': ['AZ','CO','ID','MT','NV','NM','UT','WY','AK','CA','HI','OR','WA'],\n",
    "        'south': ['DE','FL','GA','MD','NC','SC','VA','DC','WV','AL','KY','MS','TN','AR','LA','OK','TX', 'PR']\n",
    "    }\n",
    "    \n",
    "    US_STATE_CODES = ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'PR', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "    # https://en.wikipedia.org/wiki/List_of_regions_of_the_United_States\n",
    "    SEASONS = ['winter','spring','summer','autumn']\n",
    "    STAT_CAUSE_CODES = list(range(1,14))\n",
    "    \n",
    "    def __init__(self, fname, year):\n",
    "        self.cleaned = False\n",
    "        self.year = year\n",
    "        with open(fname) as csvfile:\n",
    "            self.df = pd.read_csv(csvfile)\n",
    "            self.df = self.df[WildfireClassifier.COLS]\n",
    "        \n",
    "#         for name, group in self.df.groupby('STAT_CAUSE_DESCR'):\n",
    "#             print(name, len(group))\n",
    "#         print(self.df[['FIRE_SIZE', 'FIRE_SIZE_CLASS']].drop_duplicates())\n",
    "            \n",
    "    def get_season(self, day, Y):\n",
    "        seasons = [('winter', (date(Y,  1,  1),  date(Y,  3, 20))),\n",
    "                  ('spring', (date(Y,  3, 21),  date(Y,  6, 20))),\n",
    "                  ('summer', (date(Y,  6, 21),  date(Y,  9, 22))),\n",
    "                  ('autumn', (date(Y,  9, 23),  date(Y, 12, 20))),\n",
    "                  ('winter', (date(Y, 12, 21),  date(Y, 12, 31)))]\n",
    "        for season in seasons:\n",
    "            name = season[0]\n",
    "            start, end = season[1]\n",
    "            if (start.timetuple().tm_yday <= day <= end.timetuple().tm_yday):\n",
    "                return name\n",
    "        return None\n",
    "\n",
    "    def julian_to_datetime(self, jd_series):\n",
    "        # https://www.kaggle.com/rtatman/188-million-us-wildfires/discussion/39627#222290\n",
    "        epoch = pd.to_datetime(0, unit='s').to_julian_date()\n",
    "        return pd.to_datetime(jd_series - epoch, unit='D')\n",
    "\n",
    "    def difference_in_seconds(self):\n",
    "        start_times = self.df['DISCOVERY_TIME']\n",
    "        end_times = self.df['CONT_TIME']\n",
    "        return pd.to_datetime(end_times) - pd.to_datetime(start_times)\n",
    "\n",
    "    def num_to_time(self, num_time):\n",
    "        # num_time is in 24-hour format - so 0 to 2359\n",
    "        chars = list(str(int(num_time)))\n",
    "        res = []\n",
    "        for i in range(len(chars)-1, -1, -1):\n",
    "          res.append(chars[i])\n",
    "          if len(res) == 2:\n",
    "            res.append(\":\")\n",
    "        result = ''.join(res[::-1])\n",
    "        if len(result) == 1: result = \"00:0\" + result\n",
    "        if result[0] == \":\": result = \"00\" + result\n",
    "        return result\n",
    "    \n",
    "    def clean(self):\n",
    "        if self.cleaned: return\n",
    "        self.df = self.df.dropna(subset=WildfireClassifier.COLS)\n",
    "        self.df['CONT_TIME'] = self.df.apply(lambda row: self.num_to_time(row.CONT_TIME), axis=1)\n",
    "        self.df['DISCOVERY_TIME'] = self.df.apply(lambda row: self.num_to_time(row.DISCOVERY_TIME), axis=1)\n",
    "        self.df['CONT_DATE'] = self.df.apply(lambda row: self.julian_to_datetime(row.CONT_DATE), axis=1)\n",
    "        self.df['DISCOVERY_DATE'] = self.df.apply(lambda row: self.julian_to_datetime(row.DISCOVERY_DATE),axis=1)\n",
    "        self.df['season'] = self.df.apply(lambda row: self.get_season(row.DISCOVERY_DOY,self.year), axis=1)\n",
    "        self.df['natural_cause'] = self.df.apply(lambda row: row.STAT_CAUSE_DESCR == 'Lightning', axis=1)\n",
    "        full_disc_date = pd.to_datetime(self.df['DISCOVERY_DATE'].dt.strftime(\"%Y-%m-%d\") + ' ' + self.df['DISCOVERY_TIME'])\n",
    "        full_cont_date = pd.to_datetime(self.df['CONT_DATE'].dt.strftime(\"%Y-%m-%d\") + ' ' + self.df['CONT_TIME'])\n",
    "        self.df['duration'] = full_cont_date - full_disc_date\n",
    "\n",
    "        def get_region(state_code):\n",
    "            for region in WildfireClassifier.REGIONS:\n",
    "                if state_code in WildfireClassifier.REGIONS[region]: return region\n",
    "            print(state_code)\n",
    "            return None\n",
    "        self.df['region'] = self.df.apply(lambda row: get_region(row.STATE), axis=1)\n",
    "        \n",
    "        self.cleaned = True\n",
    "    \n",
    "    def test(self, train_frac):\n",
    "        label_names = [chr(ord('A') + i) for i in range(ord('G') - ord('A') + 1)]\n",
    "\n",
    "        def get_labels(fire_class):\n",
    "            if ord(fire_class) <= ord('C'):\n",
    "                return 0\n",
    "            if ord(fire_class) <= ord('F'):\n",
    "                return 1\n",
    "            return 2\n",
    "        # features: 'state', 'season', 'cause', 'duration' (maybe)\n",
    "        def extract_features(row):\n",
    "            regions_list = list(WildfireClassifier.REGIONS.keys())\n",
    "        #     duration_min = row.duration.days * 24 * 60 + row.duration.seconds//3600\n",
    "            return [WildfireClassifier.SEASONS.index(row.season), row.STAT_CAUSE_CODE, regions_list.index(row.region)]\n",
    "\n",
    "        feature_df = self.df[['FIRE_SIZE_CLASS','season', 'region', 'duration', 'STAT_CAUSE_CODE', 'natural_cause', 'STATE']]\n",
    "        \n",
    "        \n",
    "        X = [extract_features(row) for _,row in feature_df.iterrows()]\n",
    "        y = self.df['FIRE_SIZE_CLASS'].map(lambda fire_class: ord(fire_class) - ord('A'))\n",
    "        \n",
    "        # https://stackoverflow.com/a/4602224/8109239\n",
    "        def unison_shuffled_copies(a, b):\n",
    "            assert len(a) == len(b)\n",
    "            p = np.random.permutation(len(a))\n",
    "            return np.asarray(a)[p], np.asarray(b)[p]\n",
    "        X,y = unison_shuffled_copies(X,y)\n",
    "        \n",
    "        # Split data into training and test sets\n",
    "        TRAIN_SIZE = round(train_frac * len(X))\n",
    "        print(\"TRAIN_SIZE\", TRAIN_SIZE)\n",
    "        X_train, y_train = X[:TRAIN_SIZE], y[:TRAIN_SIZE]\n",
    "        X_test, y_test = X[TRAIN_SIZE:], y[TRAIN_SIZE:]\n",
    "\n",
    "        # Use naive bayes because features are independent of each other\n",
    "        from sklearn.naive_bayes import MultinomialNB\n",
    "        from sklearn import metrics\n",
    "        clf = MultinomialNB()\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(metrics.confusion_matrix(y_test, y_pred))\n",
    "        return metrics.accuracy_score(y_test,y_pred)\n",
    "    \n",
    "    def test2(self, train_frac):\n",
    "        label_names = [chr(ord('A') + i) for i in range(ord('G') - ord('A') + 1)]\n",
    "\n",
    "        def get_labels(fire_class):\n",
    "            if ord(fire_class) <= ord('C'):\n",
    "                return 0\n",
    "            if ord(fire_class) <= ord('F'):\n",
    "                return 1\n",
    "            return 2\n",
    "        # features: 'state', 'season', 'cause', 'duration' (maybe)\n",
    "        def extract_features(row):\n",
    "            regions_list = list(WildfireClassifier.REGIONS.keys())\n",
    "        #     duration_min = row.duration.days * 24 * 60 + row.duration.seconds//3600\n",
    "            return [WildfireClassifier.SEASONS.index(row.season), row.natural_cause, regions_list.index(row.region)]\n",
    "\n",
    "        feature_df = self.df[['FIRE_SIZE_CLASS','season', 'region', 'duration', 'STAT_CAUSE_CODE', 'natural_cause', 'STATE']]\n",
    "        \n",
    "        \n",
    "        X = [extract_features(row) for _,row in feature_df.iterrows()]\n",
    "        y = self.df['FIRE_SIZE_CLASS'].map(lambda fire_class: ord(fire_class) - ord('A'))\n",
    "        \n",
    "        # https://stackoverflow.com/a/4602224/8109239\n",
    "        def unison_shuffled_copies(a, b):\n",
    "            assert len(a) == len(b)\n",
    "            p = np.random.permutation(len(a))\n",
    "            return np.asarray(a)[p], np.asarray(b)[p]\n",
    "        X,y = unison_shuffled_copies(X,y)\n",
    "        \n",
    "        # Split data into training and test sets\n",
    "        TRAIN_SIZE = round(train_frac * len(X))\n",
    "        print(\"TRAIN_SIZE\", TRAIN_SIZE)\n",
    "        X_train, y_train = X[:TRAIN_SIZE], y[:TRAIN_SIZE]\n",
    "        X_test, y_test = X[TRAIN_SIZE:], y[TRAIN_SIZE:]\n",
    "\n",
    "        # Use naive bayes because features are independent of each other\n",
    "        from sklearn.naive_bayes import MultinomialNB\n",
    "        from sklearn import metrics\n",
    "        clf = MultinomialNB()\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(metrics.confusion_matrix(y_test, y_pred))\n",
    "        return metrics.accuracy_score(y_test,y_pred)\n",
    "\n",
    "    def test3(self, train_frac):\n",
    "        label_names = [chr(ord('A') + i) for i in range(ord('G') - ord('A') + 1)]\n",
    "\n",
    "        def get_labels(fire_class):\n",
    "            if ord(fire_class) <= ord('C'):\n",
    "                return 0\n",
    "            if ord(fire_class) <= ord('F'):\n",
    "                return 1\n",
    "            return 2\n",
    "        # features: 'state', 'season', 'cause', 'duration' (maybe)\n",
    "        def extract_features(row):\n",
    "            regions_list = list(WildfireClassifier.REGIONS.keys())\n",
    "        #     duration_min = row.duration.days * 24 * 60 + row.duration.seconds//3600\n",
    "            return [WildfireClassifier.SEASONS.index(row.season), row.STAT_CAUSE_CODE, regions_list.index(row.region)]\n",
    "\n",
    "        feature_df = self.df[['FIRE_SIZE_CLASS','season', 'region', 'duration', 'STAT_CAUSE_CODE', 'natural_cause', 'STATE']]\n",
    "        \n",
    "        \n",
    "        X = [extract_features(row) for _,row in feature_df.iterrows()]\n",
    "        y = self.df['FIRE_SIZE_CLASS'].map(get_labels)\n",
    "        \n",
    "        # https://stackoverflow.com/a/4602224/8109239\n",
    "        def unison_shuffled_copies(a, b):\n",
    "            assert len(a) == len(b)\n",
    "            p = np.random.permutation(len(a))\n",
    "            return np.asarray(a)[p], np.asarray(b)[p]\n",
    "        X,y = unison_shuffled_copies(X,y)\n",
    "        \n",
    "        # Split data into training and test sets\n",
    "        TRAIN_SIZE = round(train_frac * len(X))\n",
    "        print(\"TRAIN_SIZE\", TRAIN_SIZE)\n",
    "        X_train, y_train = X[:TRAIN_SIZE], y[:TRAIN_SIZE]\n",
    "        X_test, y_test = X[TRAIN_SIZE:], y[TRAIN_SIZE:]\n",
    "\n",
    "        # Use naive bayes because features are independent of each other\n",
    "        from sklearn.naive_bayes import MultinomialNB\n",
    "        from sklearn import metrics\n",
    "        clf = MultinomialNB()\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "#         print(metrics.confusion_matrix(y_test, y_pred))\n",
    "        self.get_cause_labels()\n",
    "        return metrics.accuracy_score(y_test,y_pred)\n",
    "    \n",
    "    def save_cleaned_data(self, path):\n",
    "        if not self.cleaned: self.clean()\n",
    "        df = self.df['season', 'region', 'STAT_CAUSE_CODE', 'duration']\n",
    "        df.to_csv(path, index=False)\n",
    "    \n",
    "    def get_cause_labels(self):\n",
    "        df = self.df[['STAT_CAUSE_CODE', 'STAT_CAUSE_DESCR']]\n",
    "        print(df.unique())\n",
    "    \n",
    "clf_1992 = WildfireClassifier('./wildfires_1992.csv', 2000)\n",
    "clf_1992.clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SIZE 21619\n",
      "[[4027 2068    0    0    0    0    0]\n",
      " [1862 4442    0    0    0    0    0]\n",
      " [ 369 1281    0    0    0    0    0]\n",
      " [  63  124    0    0    0    0    0]\n",
      " [  50   53    0    0    0    0    0]\n",
      " [  37   18    0    0    0    0    0]\n",
      " [  13    5    0    0    0    0    0]]\n",
      "0.587635303913\n"
     ]
    }
   ],
   "source": [
    "print(clf_1992.test(.6))\n",
    "# print(clf_1992.test2(.6))\n",
    "# print(clf_1992.test3(.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STAT_CAUSE_DESCR</th>\n",
       "      <th>STAT_CAUSE_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lightning</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Campfire</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Equipment Use</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Debris Burning</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Smoking</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Arson</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>Railroad</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>Children</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11452</th>\n",
       "      <td>Structure</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11483</th>\n",
       "      <td>Powerline</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11488</th>\n",
       "      <td>Fireworks</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16054</th>\n",
       "      <td>Missing/Undefined</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        STAT_CAUSE_DESCR  STAT_CAUSE_CODE\n",
       "0              Lightning              1.0\n",
       "2               Campfire              4.0\n",
       "16         Equipment Use              2.0\n",
       "21        Debris Burning              5.0\n",
       "23               Smoking              3.0\n",
       "24                 Arson              7.0\n",
       "96         Miscellaneous              9.0\n",
       "683             Railroad              6.0\n",
       "759             Children              8.0\n",
       "11452          Structure             12.0\n",
       "11483          Powerline             11.0\n",
       "11488          Fireworks             10.0\n",
       "16054  Missing/Undefined             13.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_1992.df[['STAT_CAUSE_DESCR','STAT_CAUSE_CODE']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (10,11,12,18,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SIZE 28825\n",
      "[[2014  969    0    0    0    0    0]\n",
      " [1016 2230    0    0    0    0    0]\n",
      " [ 169  630    0    0    0    0    0]\n",
      " [  35   63    0    0    0    0    0]\n",
      " [  24   19    0    0    0    0    0]\n",
      " [  14   12    0    0    0    0    0]\n",
      " [   9    2    0    0    0    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (10,11,12,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SIZE 26813\n",
      "[[ 885 1529    0    0    0    0    0]\n",
      " [ 594 2720    0    0    0    0    0]\n",
      " [  97  708    0    0    0    0    0]\n",
      " [  14   79    0    0    0    0    0]\n",
      " [   7   29    0    0    0    0    0]\n",
      " [  17   10    0    0    0    0    0]\n",
      " [   5    9    0    0    0    0    0]]\n",
      "TRAIN_SIZE 32772\n",
      "[[2165 1176    0    0    0    0    0]\n",
      " [1289 2281    0    0    0    0    0]\n",
      " [ 269  667    0    0    0    0    0]\n",
      " [  84   80    0    0    0    0    0]\n",
      " [  64   35    0    0    0    0    0]\n",
      " [  43   15    0    0    0    0    0]\n",
      " [  23    2    0    0    0    0    0]]\n",
      "TRAIN_SIZE 29474\n",
      "[[1283 1313    0    0    0    0    0]\n",
      " [ 886 2722    0    0    0    0    0]\n",
      " [ 219  718    0    0    0    0    0]\n",
      " [  38   76    0    0    0    0    0]\n",
      " [  25   39    0    0    0    0    0]\n",
      " [  21   14    0    0    0    0    0]\n",
      " [  10    5    0    0    0    0    0]]\n",
      "TRAIN_SIZE 33466\n",
      "[[1886 1234    0    0    0    0    0]\n",
      " [1218 2655    0    0    0    0    0]\n",
      " [ 227  791    0    0    0    0    0]\n",
      " [  62  108    0    0    0    0    0]\n",
      " [  48   45    0    0    0    0    0]\n",
      " [  33   18    0    0    0    0    0]\n",
      " [  27   15    0    0    0    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (11,12,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SIZE 20697\n",
      "[[1408  821    0    0    0    0    0]\n",
      " [ 887 1422    0    0    0    0    0]\n",
      " [ 199  326    0    0    0    0    0]\n",
      " [  27   34    0    0    0    0    0]\n",
      " [  20   12    0    0    0    0    0]\n",
      " [   8    4    0    0    0    0    0]\n",
      " [   4    2    0    0    0    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (11,12,18,35,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SIZE 19427\n",
      "[[1425  744    0    0    0    0    0]\n",
      " [ 855 1187    0    0    0    0    0]\n",
      " [ 199  287    0    0    0    0    0]\n",
      " [  41   36    0    0    0    0    0]\n",
      " [  34   10    0    0    0    0    0]\n",
      " [  21    8    0    0    0    0    0]\n",
      " [   8    2    0    0    0    0    0]]\n",
      "TRAIN_SIZE 23589\n",
      "[[1532  899    0    0    0    0    0]\n",
      " [1069 1428    0    0    0    0    0]\n",
      " [ 289  406    0    0    0    0    0]\n",
      " [  64   57    0    0    0    0    0]\n",
      " [  55   27    0    0    0    0    0]\n",
      " [  38   13    0    0    0    0    0]\n",
      " [  17    3    0    0    0    0    0]]\n",
      "TRAIN_SIZE 30087\n",
      "[[2060 1213    0    0    0    0    0]\n",
      " [1381 1947    0    0    0    0    0]\n",
      " [ 248  371    0    0    0    0    0]\n",
      " [  64   57    0    0    0    0    0]\n",
      " [  52   29    0    0    0    0    0]\n",
      " [  39   13    0    0    0    0    0]\n",
      " [  37   11    0    0    0    0    0]]\n",
      "TRAIN_SIZE 29607\n",
      "[[2138 1215    0    0    0    0    0]\n",
      " [1444 1870    0    0    0    0    0]\n",
      " [ 234  286    0    0    0    0    0]\n",
      " [  61   39    0    0    0    0    0]\n",
      " [  33   17    0    0    0    0    0]\n",
      " [  31   12    0    0    0    0    0]\n",
      " [  17    5    0    0    0    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SIZE 28286\n",
      "[[1942 1312    0    0    0    0    0]\n",
      " [1121 1936    0    0    0    0    0]\n",
      " [ 212  355    0    0    0    0    0]\n",
      " [  40   47    0    0    0    0    0]\n",
      " [  24   21    0    0    0    0    0]\n",
      " [  20   14    0    0    0    0    0]\n",
      " [  25    3    0    0    0    0    0]]\n",
      "TRAIN_SIZE 25471\n",
      "[[2405  924    0    0    0    0    0]\n",
      " [1176 1192    0    0    0    0    0]\n",
      " [ 250  194    0    0    0    0    0]\n",
      " [  54   47    0    0    0    0    0]\n",
      " [  38   22    0    0    0    0    0]\n",
      " [  34   12    0    0    0    0    0]\n",
      " [  18    2    0    0    0    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (12,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SIZE 22231\n",
      "[[2259  753    0    0    0    0    0]\n",
      " [ 998  938    0    0    0    0    0]\n",
      " [ 198  272    0    0    0    0    0]\n",
      " [  30   33    0    0    0    0    0]\n",
      " [  15   19    0    0    0    0    0]\n",
      " [  17    3    0    0    0    0    0]\n",
      " [  21    2    0    0    0    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (10,12,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SIZE 26642\n",
      "[[2539  438    0    0    0    0    0]\n",
      " [1802  950    0    0    0    0    0]\n",
      " [ 326  297    0    0    0    0    0]\n",
      " [  90   55    0    0    0    0    0]\n",
      " [  56   23    0    0    0    0    0]\n",
      " [  37    9    0    0    0    0    0]\n",
      " [  36    2    0    0    0    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (11,12,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SIZE 30328\n",
      "[[2229 1241    0    0    0    0    0]\n",
      " [1355 1621    0    0    0    0    0]\n",
      " [ 394  376    0    0    0    0    0]\n",
      " [  89   63    0    0    0    0    0]\n",
      " [  54   40    0    0    0    0    0]\n",
      " [  55   24    0    0    0    0    0]\n",
      " [  32    9    0    0    0    0    0]]\n",
      "TRAIN_SIZE 28488\n",
      "[[2725  590    0    0    0    0    0]\n",
      " [1839  967    0    0    0    0    0]\n",
      " [ 310  420    0    0    0    0    0]\n",
      " [  64   64    0    0    0    0    0]\n",
      " [  46   22    0    0    0    0    0]\n",
      " [  32   13    0    0    0    0    0]\n",
      " [  29    1    0    0    0    0    0]]\n",
      "TRAIN_SIZE 23106\n",
      "[[1858  786    0    0    0    0    0]\n",
      " [1246 1134    0    0    0    0    0]\n",
      " [ 274  264    0    0    0    0    0]\n",
      " [  42   42    0    0    0    0    0]\n",
      " [  25   20    0    0    0    0    0]\n",
      " [  29   25    0    0    0    0    0]\n",
      " [  21   10    0    0    0    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SIZE 26587\n",
      "[[2281  763    0    0    0    0    0]\n",
      " [1267 1321    0    0    0    0    0]\n",
      " [ 230  482    0    0    0    0    0]\n",
      " [  62   81    0    0    0    0    0]\n",
      " [  45   43    0    0    0    0    0]\n",
      " [  23   26    0    0    0    0    0]\n",
      " [  15    8    0    0    0    0    0]]\n",
      "TRAIN_SIZE 23578\n",
      "[[1315 1141    0    0    0    0    0]\n",
      " [ 894 1615    0    0    0    0    0]\n",
      " [ 261  428    0    0    0    0    0]\n",
      " [  52   68    0    0    0    0    0]\n",
      " [  24   42    0    0    0    0    0]\n",
      " [  26   17    0    0    0    0    0]\n",
      " [  11    1    0    0    0    0    0]]\n",
      "TRAIN_SIZE 46797\n",
      "[[1028 2969    0    0    0    0    0]\n",
      " [ 617 5039    0    0    0    0    0]\n",
      " [ 100 1414    0    0    0    0    0]\n",
      " [  14  225    0    0    0    0    0]\n",
      " [   5  134    0    0    0    0    0]\n",
      " [   3  100    0    0    0    0    0]\n",
      " [   1   50    0    0    0    0    0]]\n",
      "TRAIN_SIZE 40771\n",
      "[[1517 2588    0    0    0    0    0]\n",
      " [1295 3291    0    0    0    0    0]\n",
      " [ 264  821    0    0    0    0    0]\n",
      " [  46  119    0    0    0    0    0]\n",
      " [  32   67    0    0    0    0    0]\n",
      " [  15   77    0    0    0    0    0]\n",
      " [   9   52    0    0    0    0    0]]\n",
      "TRAIN_SIZE 36222\n",
      "[[3253 1072    0    0    0    0    0]\n",
      " [2136 1661    0    0    0    0    0]\n",
      " [ 334  393    0    0    0    0    0]\n",
      " [  61   43    0    0    0    0    0]\n",
      " [  31   17    0    0    0    0    0]\n",
      " [  28    2    0    0    0    0    0]\n",
      " [  21    3    0    0    0    0    0]]\n",
      "TRAIN_SIZE 38250\n",
      "[[2552 1432    0    0    0    0    0]\n",
      " [1828 2523    0    0    0    0    0]\n",
      " [ 310  687    0    0    0    0    0]\n",
      " [  53   65    0    0    0    0    0]\n",
      " [  22   25    0    0    0    0    0]\n",
      " [  28   18    0    0    0    0    0]\n",
      " [  13    6    0    0    0    0    0]]\n",
      "TRAIN_SIZE 42091\n",
      "[[2352 2107    0    0    0    0    0]\n",
      " [1809 2803    0    0    0    0    0]\n",
      " [ 331  796    0    0    0    0    0]\n",
      " [  49  115    0    0    0    0    0]\n",
      " [  19   51    0    0    0    0    0]\n",
      " [  13   37    0    0    0    0    0]\n",
      " [   4   37    0    0    0    0    0]]\n",
      "[[1992, 0.5889536497363308], [1993, 0.53781888706549308], [1994, 0.54265836689857194], [1995, 0.54349301126340077], [1996, 0.54272738137922794], [1997, 0.54696559721685345], [1998, 0.53778052295655754], [1999, 0.50195014414108874], [2000, 0.53270406806700343], [2001, 0.54147527695217512], [2002, 0.54835972850678738], [2003, 0.56485552763819091], [2004, 0.57520690896005755], [2005, 0.52387387387387385], [2006, 0.50778158797151152], [2007, 0.51839370963212583], [2008, 0.51800554016620504], [2009, 0.54189860087257413], [2010, 0.49703138252756573], [2011, 0.51859133259252932], [2012, 0.47169626214068477], [2013, 0.54268360022087248], [2014, 0.53074670571010252], [2015, 0.48987931198327472]]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for year in range(1992,2016):\n",
    "    clf = WildfireClassifier('./wildfires_%d.csv' % year, year)\n",
    "#     clf.train()\n",
    "    clf.clean()\n",
    "    result.append([year, clf.test(0.8)])\n",
    "print(result)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (9,11,12,13,14,15,16,17,18,19,36,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "with open('./wildfires.csv') as csvfile:\n",
    "    df = pd.read_csv(csvfile)\n",
    "    pairs = df[['STAT_CAUSE_DESCR','FIRE_SIZE_CLASS']].drop_duplicates()\n",
    "    res = []\n",
    "    for _, x in pairs.iterrows(): \n",
    "        cause, size_class = x['STAT_CAUSE_DESCR'], x['FIRE_SIZE_CLASS']\n",
    "        count = len(df[(df.STAT_CAUSE_DESCR==cause)&(df.FIRE_SIZE_CLASS==size_class)])\n",
    "        res.append([cause, size_class, count])\n",
    "    new_df = pd.DataFrame(data=res, columns=['cause','size_class','count'])\n",
    "    with open('./cause_to_size.csv', \"w\") as csvtowrite:\n",
    "        new_df.to_csv(csvtowrite, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (9,11,12,13,14,15,16,17,18,19,36,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "with open('./wildfires.csv') as csvfile:\n",
    "    df = pd.read_csv(csvfile)\n",
    "    pairs = df[['FIRE_SIZE_CLASS','STATE']].drop_duplicates()\n",
    "    res = []\n",
    "    for _, x in pairs.iterrows(): \n",
    "        size_class, state = x['FIRE_SIZE_CLASS'], x['STATE']\n",
    "        count = len(df[(df.FIRE_SIZE_CLASS==size_class)&(df.STATE==state)])\n",
    "        res.append([size_class, state, count])\n",
    "    new_df = pd.DataFrame(data=res, columns=['size_class','state','count'])\n",
    "    with open('./size_to_state.csv', \"w\") as csvtowrite:\n",
    "        new_df.to_csv(csvtowrite, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
